{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vkkGaV80fWXVli77nUWuylrwhmpXeTpF",
      "authorship_tag": "ABX9TyNWJEDPLzsvjnnbedF/RSz9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deborahsag/Updated-Music-Transformer/blob/structureness-indicators/Music_Transformer_(from_Git).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "BI215HhzuHbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone Git branch"
      ],
      "metadata": {
        "id": "5coGJuDiuLYZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzwJatyFuBeN",
        "outputId": "dd3676a1-a02c-4c14-bb5b-a8e4a1c3aff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Updated-Music-Transformer'...\n",
            "remote: Enumerating objects: 156, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 156 (delta 30), reused 92 (delta 18), pack-reused 49\u001b[K\n",
            "Receiving objects: 100% (156/156), 105.40 MiB | 27.57 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone -b structureness-indicators --single-branch https://github.com/deborahsag/Updated-Music-Transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmfnaSvWMplh",
        "outputId": "d2e0bcd9-f453-4fe4-e3e8-91c404243beb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('Updated-Music-Transformer')"
      ],
      "metadata": {
        "id": "RMRBQyOHHFS0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fvDzhACxW-8",
        "outputId": "d755d61b-9c46-498c-ebcc-6983f47fc9c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auxiliars\t\t       model\n",
            "dataset\t\t\t       mueller_audio_tools\n",
            "evaluate.py\t\t       pitch_class_entropy.py\n",
            "generate_multiple_original.py  preprocess_midi.py\n",
            "generate_multiple.py\t       structureness_indicators.py\n",
            "generate_multiple_tpu.py       third_party\n",
            "generate.py\t\t       trained_models\n",
            "generic_preprocess_midi.py     train.py\n",
            "graph_results.py\t       utilities\n",
            "midi_processor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirements"
      ],
      "metadata": {
        "id": "Y8H8xyV2HdCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install pretty_midi\n",
        "! pip3 install midi2audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkkX-86XHgH4",
        "outputId": "d458133a-883e-4bbe-b7fc-a1b539db80d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from pretty_midi) (1.22.4)\n",
            "Collecting mido>=1.1.16\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from pretty_midi) (1.15.0)\n",
            "Building wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592303 sha256=d70218bcdc2064a048fa6eca6669c96213f8ad1bdf811c611333f3c4f2853c9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/ec/20/b8e937a5bcf1de547ea5ce465db7de7f6761e15e6f0a01e25f\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.2.10 pretty_midi-0.2.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting midi2audio\n",
            "  Downloading midi2audio-0.1.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: midi2audio\n",
            "Successfully installed midi2audio-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset (saved in Google Drive)"
      ],
      "metadata": {
        "id": "5rgQ6egQLrHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = '../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro'"
      ],
      "metadata": {
        "id": "BOko38MqxzUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training and evaluation"
      ],
      "metadata": {
        "id": "p6-IEZopnOfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 train.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EYIcgOLnSFF",
        "outputId": "10b7b65d-bf5e-4423-e463-02fbe8146842"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 390\n",
            "usage: train.py\n",
            "       [-h]\n",
            "       [-input_dir INPUT_DIR]\n",
            "       [-output_dir OUTPUT_DIR]\n",
            "       [-weight_modulus WEIGHT_MODULUS]\n",
            "       [-print_modulus PRINT_MODULUS]\n",
            "       [-n_workers N_WORKERS]\n",
            "       [--force_cpu]\n",
            "       [--no_tensorboard]\n",
            "       [-continue_weights CONTINUE_WEIGHTS]\n",
            "       [-continue_epoch CONTINUE_EPOCH]\n",
            "       [-lr LR]\n",
            "       [-ce_smoothing CE_SMOOTHING]\n",
            "       [-batch_size BATCH_SIZE]\n",
            "       [-epochs EPOCHS]\n",
            "       [--rpr]\n",
            "       [--pmp]\n",
            "       [-max_sequence MAX_SEQUENCE]\n",
            "       [-n_layers N_LAYERS]\n",
            "       [-num_heads NUM_HEADS]\n",
            "       [-d_model D_MODEL]\n",
            "       [-dim_feedforward DIM_FEEDFORWARD]\n",
            "       [-dropout DROPOUT]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  -input_dir INPUT_DIR\n",
            "    Folder of p\n",
            "    reprocessed\n",
            "    and pickled\n",
            "    midi files\n",
            "  -output_dir OUTPUT_DIR\n",
            "    Folder to\n",
            "    save model\n",
            "    weights.\n",
            "    Saves one\n",
            "    every epoch\n",
            "  -weight_modulus WEIGHT_MODULUS\n",
            "    How often\n",
            "    to save\n",
            "    epoch\n",
            "    weights\n",
            "    (ex: value\n",
            "    of 10 means\n",
            "    save every\n",
            "    10 epochs)\n",
            "  -print_modulus PRINT_MODULUS\n",
            "    How often\n",
            "    to print\n",
            "    train\n",
            "    results for\n",
            "    a batch\n",
            "    (batch\n",
            "    loss, learn\n",
            "    rate, etc.)\n",
            "  -n_workers N_WORKERS\n",
            "    Number of\n",
            "    threads for\n",
            "    the\n",
            "    dataloader\n",
            "  --force_cpu\n",
            "    Forces\n",
            "    model to\n",
            "    run on a\n",
            "    cpu even\n",
            "    when gpu is\n",
            "    available\n",
            "  --no_tensorboard\n",
            "    Turns off\n",
            "    tensorboard\n",
            "    result\n",
            "    reporting\n",
            "  -continue_weights CONTINUE_WEIGHTS\n",
            "    Model\n",
            "    weights to\n",
            "    continue\n",
            "    training\n",
            "    based on\n",
            "  -continue_epoch CONTINUE_EPOCH\n",
            "    Epoch the c\n",
            "    ontinue_wei\n",
            "    ghts model\n",
            "    was at\n",
            "  -lr LR\n",
            "    Constant\n",
            "    learn rate.\n",
            "    Leave as\n",
            "    None for a\n",
            "    custom\n",
            "    scheduler.\n",
            "  -ce_smoothing CE_SMOOTHING\n",
            "    Smoothing\n",
            "    parameter\n",
            "    for\n",
            "    smoothed\n",
            "    cross\n",
            "    entropy\n",
            "    loss\n",
            "    (defaults\n",
            "    to no\n",
            "    smoothing)\n",
            "  -batch_size BATCH_SIZE\n",
            "    Batch size\n",
            "    to use\n",
            "  -epochs EPOCHS\n",
            "    Number of\n",
            "    epochs to\n",
            "    use\n",
            "  --rpr\n",
            "    Use a\n",
            "    modified\n",
            "    Transformer\n",
            "    for\n",
            "    Relative\n",
            "    Position Re\n",
            "    presentatio\n",
            "    ns\n",
            "  --pmp\n",
            "    Use the\n",
            "    Pan-Matrix\n",
            "    Profile in\n",
            "    the model\n",
            "  -max_sequence MAX_SEQUENCE\n",
            "    Maximum\n",
            "    midi\n",
            "    sequence to\n",
            "    consider\n",
            "  -n_layers N_LAYERS\n",
            "    Number of\n",
            "    decoder\n",
            "    layers to\n",
            "    use\n",
            "  -num_heads NUM_HEADS\n",
            "    Number of\n",
            "    heads to\n",
            "    use for\n",
            "    multi-head\n",
            "    attention\n",
            "  -d_model D_MODEL\n",
            "    Dimension\n",
            "    of the\n",
            "    model\n",
            "    (output dim\n",
            "    of\n",
            "    embedding\n",
            "    layers,\n",
            "    etc.)\n",
            "  -dim_feedforward DIM_FEEDFORWARD\n",
            "    Dimension\n",
            "    of the\n",
            "    feedforward\n",
            "    layer\n",
            "  -dropout DROPOUT\n",
            "    Dropout\n",
            "    rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! python3 train.py -input_dir '../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro' -output_dir '../drive/MyDrive/Music Transformer/new-weights' -epochs 100 --rpr -max_sequence 2048 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqqJPF8onXxJ",
        "outputId": "2da65408-4a94-45ce-e197-f5c7d489f054"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "LR: 0.0004109352773598294\n",
            "Train loss: 2.1047229766845703\n",
            "\n",
            "Time (s): 0.5089049339294434\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 47 / 480\n",
            "LR: 0.00041091751371500474\n",
            "Train loss: 2.4512929916381836\n",
            "\n",
            "Time (s): 0.5083293914794922\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 48 / 480\n",
            "LR: 0.00041089975237360704\n",
            "Train loss: 1.996286392211914\n",
            "\n",
            "Time (s): 0.5122990608215332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 49 / 480\n",
            "LR: 0.00041088199333513847\n",
            "Train loss: 2.3729207515716553\n",
            "\n",
            "Time (s): 0.5132050514221191\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 50 / 480\n",
            "LR: 0.00041086423659910146\n",
            "Train loss: 2.129716396331787\n",
            "\n",
            "Time (s): 0.5088112354278564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 51 / 480\n",
            "LR: 0.00041084648216499866\n",
            "Train loss: 2.3023171424865723\n",
            "\n",
            "Time (s): 0.5086944103240967\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 52 / 480\n",
            "LR: 0.0004108287300323326\n",
            "Train loss: 2.275765895843506\n",
            "\n",
            "Time (s): 0.5071084499359131\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 53 / 480\n",
            "LR: 0.0004108109802006062\n",
            "Train loss: 2.0305111408233643\n",
            "\n",
            "Time (s): 0.5081987380981445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 54 / 480\n",
            "LR: 0.00041079323266932235\n",
            "Train loss: 2.281174659729004\n",
            "\n",
            "Time (s): 0.511972188949585\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 55 / 480\n",
            "LR: 0.0004107754874379843\n",
            "Train loss: 2.434307336807251\n",
            "\n",
            "Time (s): 0.5115387439727783\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 56 / 480\n",
            "LR: 0.0004107577445060952\n",
            "Train loss: 2.3483941555023193\n",
            "\n",
            "Time (s): 0.5163259506225586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 57 / 480\n",
            "LR: 0.0004107400038731586\n",
            "Train loss: 2.045708417892456\n",
            "\n",
            "Time (s): 0.5093703269958496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 58 / 480\n",
            "LR: 0.0004107222655386781\n",
            "Train loss: 2.1857657432556152\n",
            "\n",
            "Time (s): 0.5114247798919678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 59 / 480\n",
            "LR: 0.00041070452950215725\n",
            "Train loss: 2.224470615386963\n",
            "\n",
            "Time (s): 0.5138764381408691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 60 / 480\n",
            "LR: 0.00041068679576310017\n",
            "Train loss: 2.343698740005493\n",
            "\n",
            "Time (s): 0.507401704788208\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 61 / 480\n",
            "LR: 0.0004106690643210107\n",
            "Train loss: 1.897748589515686\n",
            "\n",
            "Time (s): 0.5074787139892578\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 62 / 480\n",
            "LR: 0.0004106513351753932\n",
            "Train loss: 2.2468860149383545\n",
            "\n",
            "Time (s): 0.5144352912902832\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 63 / 480\n",
            "LR: 0.00041063360832575184\n",
            "Train loss: 2.2177369594573975\n",
            "\n",
            "Time (s): 0.5150625705718994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 64 / 480\n",
            "LR: 0.00041061588377159114\n",
            "Train loss: 2.2859983444213867\n",
            "\n",
            "Time (s): 0.5182895660400391\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 65 / 480\n",
            "LR: 0.0004105981615124158\n",
            "Train loss: 2.0951287746429443\n",
            "\n",
            "Time (s): 0.514937162399292\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 66 / 480\n",
            "LR: 0.0004105804415477306\n",
            "Train loss: 2.0008389949798584\n",
            "\n",
            "Time (s): 0.5235474109649658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 67 / 480\n",
            "LR: 0.0004105627238770404\n",
            "Train loss: 2.238084316253662\n",
            "\n",
            "Time (s): 0.5231244564056396\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 68 / 480\n",
            "LR: 0.00041054500849985035\n",
            "Train loss: 2.0990712642669678\n",
            "\n",
            "Time (s): 0.5292434692382812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 69 / 480\n",
            "LR: 0.00041052729541566567\n",
            "Train loss: 2.2870142459869385\n",
            "\n",
            "Time (s): 0.5145468711853027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 70 / 480\n",
            "LR: 0.00041050958462399167\n",
            "Train loss: 2.183528423309326\n",
            "\n",
            "Time (s): 0.5095517635345459\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 71 / 480\n",
            "LR: 0.00041049187612433397\n",
            "Train loss: 2.068897008895874\n",
            "\n",
            "Time (s): 0.5078434944152832\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 72 / 480\n",
            "LR: 0.0004104741699161982\n",
            "Train loss: 2.2626571655273438\n",
            "\n",
            "Time (s): 0.511145830154419\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 73 / 480\n",
            "LR: 0.0004104564659990902\n",
            "Train loss: 2.1261146068573\n",
            "\n",
            "Time (s): 0.5064465999603271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 74 / 480\n",
            "LR: 0.00041043876437251597\n",
            "Train loss: 2.11989164352417\n",
            "\n",
            "Time (s): 0.507319450378418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 75 / 480\n",
            "LR: 0.00041042106503598165\n",
            "Train loss: 2.184340715408325\n",
            "\n",
            "Time (s): 0.5050771236419678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 76 / 480\n",
            "LR: 0.0004104033679889935\n",
            "Train loss: 2.2612268924713135\n",
            "\n",
            "Time (s): 0.5134003162384033\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 77 / 480\n",
            "LR: 0.00041038567323105785\n",
            "Train loss: 1.8482496738433838\n",
            "\n",
            "Time (s): 0.5076334476470947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 78 / 480\n",
            "LR: 0.00041036798076168136\n",
            "Train loss: 1.9945192337036133\n",
            "\n",
            "Time (s): 0.5086791515350342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 79 / 480\n",
            "LR: 0.00041035029058037083\n",
            "Train loss: 2.035865306854248\n",
            "\n",
            "Time (s): 0.5093235969543457\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 80 / 480\n",
            "LR: 0.000410332602686633\n",
            "Train loss: 2.082754135131836\n",
            "\n",
            "Time (s): 0.5099337100982666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 81 / 480\n",
            "LR: 0.00041031491707997484\n",
            "Train loss: 2.0153839588165283\n",
            "\n",
            "Time (s): 0.5093796253204346\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 82 / 480\n",
            "LR: 0.00041029723375990375\n",
            "Train loss: 2.4114866256713867\n",
            "\n",
            "Time (s): 0.508246660232544\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 83 / 480\n",
            "LR: 0.0004102795527259269\n",
            "Train loss: 2.2680797576904297\n",
            "\n",
            "Time (s): 0.5085511207580566\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 84 / 480\n",
            "LR: 0.0004102618739775517\n",
            "Train loss: 2.3615057468414307\n",
            "\n",
            "Time (s): 0.507194995880127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 85 / 480\n",
            "LR: 0.00041024419751428594\n",
            "Train loss: 2.0487523078918457\n",
            "\n",
            "Time (s): 0.5128879547119141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 86 / 480\n",
            "LR: 0.00041022652333563717\n",
            "Train loss: 2.118112802505493\n",
            "\n",
            "Time (s): 0.5136713981628418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 87 / 480\n",
            "LR: 0.00041020885144111343\n",
            "Train loss: 2.09318208694458\n",
            "\n",
            "Time (s): 0.5090911388397217\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 88 / 480\n",
            "LR: 0.0004101911818302229\n",
            "Train loss: 2.0001604557037354\n",
            "\n",
            "Time (s): 0.5098912715911865\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 89 / 480\n",
            "LR: 0.0004101735145024735\n",
            "Train loss: 2.180936574935913\n",
            "\n",
            "Time (s): 0.5156521797180176\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 90 / 480\n",
            "LR: 0.0004101558494573738\n",
            "Train loss: 2.096652030944824\n",
            "\n",
            "Time (s): 0.5187492370605469\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 91 / 480\n",
            "LR: 0.0004101381866944322\n",
            "Train loss: 2.0542068481445312\n",
            "\n",
            "Time (s): 0.5143024921417236\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 92 / 480\n",
            "LR: 0.0004101205262131575\n",
            "Train loss: 2.028895378112793\n",
            "\n",
            "Time (s): 0.5130081176757812\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 93 / 480\n",
            "LR: 0.00041010286801305827\n",
            "Train loss: 2.5198633670806885\n",
            "\n",
            "Time (s): 0.5133020877838135\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 94 / 480\n",
            "LR: 0.00041008521209364373\n",
            "Train loss: 2.1915464401245117\n",
            "\n",
            "Time (s): 0.5113368034362793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 95 / 480\n",
            "LR: 0.0004100675584544227\n",
            "Train loss: 2.1797001361846924\n",
            "\n",
            "Time (s): 0.5239992141723633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 96 / 480\n",
            "LR: 0.0004100499070949047\n",
            "Train loss: 2.1276819705963135\n",
            "\n",
            "Time (s): 0.5080616474151611\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 97 / 480\n",
            "LR: 0.0004100322580145988\n",
            "Train loss: 2.4273488521575928\n",
            "\n",
            "Time (s): 0.5088827610015869\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 98 / 480\n",
            "LR: 0.0004100146112130149\n",
            "Train loss: 2.0483198165893555\n",
            "\n",
            "Time (s): 0.505659818649292\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 99 / 480\n",
            "LR: 0.00040999696668966244\n",
            "Train loss: 2.0849010944366455\n",
            "\n",
            "Time (s): 0.5095343589782715\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 100 / 480\n",
            "LR: 0.00040997932444405125\n",
            "Train loss: 2.3683993816375732\n",
            "\n",
            "Time (s): 0.5148255825042725\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 101 / 480\n",
            "LR: 0.0004099616844756915\n",
            "Train loss: 2.1325950622558594\n",
            "\n",
            "Time (s): 0.5086524486541748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 102 / 480\n",
            "LR: 0.0004099440467840932\n",
            "Train loss: 2.6414082050323486\n",
            "\n",
            "Time (s): 0.5098481178283691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 103 / 480\n",
            "LR: 0.00040992641136876665\n",
            "Train loss: 2.0581531524658203\n",
            "\n",
            "Time (s): 0.510443925857544\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 104 / 480\n",
            "LR: 0.00040990877822922223\n",
            "Train loss: 2.2047667503356934\n",
            "\n",
            "Time (s): 0.5090367794036865\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 105 / 480\n",
            "LR: 0.0004098911473649706\n",
            "Train loss: 2.149369239807129\n",
            "\n",
            "Time (s): 0.511894702911377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 106 / 480\n",
            "LR: 0.0004098735187755224\n",
            "Train loss: 2.404491424560547\n",
            "\n",
            "Time (s): 0.5085654258728027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 107 / 480\n",
            "LR: 0.0004098558924603885\n",
            "Train loss: 2.3141398429870605\n",
            "\n",
            "Time (s): 0.5123717784881592\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 108 / 480\n",
            "LR: 0.00040983826841908003\n",
            "Train loss: 2.3766932487487793\n",
            "\n",
            "Time (s): 0.5103728771209717\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 109 / 480\n",
            "LR: 0.000409820646651108\n",
            "Train loss: 2.2004220485687256\n",
            "\n",
            "Time (s): 0.506800651550293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 110 / 480\n",
            "LR: 0.0004098030271559839\n",
            "Train loss: 2.202194929122925\n",
            "\n",
            "Time (s): 0.5040290355682373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 111 / 480\n",
            "LR: 0.00040978540993321896\n",
            "Train loss: 2.221869707107544\n",
            "\n",
            "Time (s): 0.5064165592193604\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 112 / 480\n",
            "LR: 0.000409767794982325\n",
            "Train loss: 2.1006250381469727\n",
            "\n",
            "Time (s): 0.505211591720581\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 113 / 480\n",
            "LR: 0.00040975018230281364\n",
            "Train loss: 2.130100727081299\n",
            "\n",
            "Time (s): 0.5094339847564697\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 114 / 480\n",
            "LR: 0.00040973257189419677\n",
            "Train loss: 2.137911558151245\n",
            "\n",
            "Time (s): 0.5109043121337891\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 115 / 480\n",
            "LR: 0.0004097149637559865\n",
            "Train loss: 1.838516116142273\n",
            "\n",
            "Time (s): 0.505286693572998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 116 / 480\n",
            "LR: 0.0004096973578876951\n",
            "Train loss: 2.329124689102173\n",
            "\n",
            "Time (s): 0.5214154720306396\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 117 / 480\n",
            "LR: 0.0004096797542888347\n",
            "Train loss: 1.9666521549224854\n",
            "\n",
            "Time (s): 0.5241012573242188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 118 / 480\n",
            "LR: 0.0004096621529589179\n",
            "Train loss: 2.5172927379608154\n",
            "\n",
            "Time (s): 0.5257899761199951\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 119 / 480\n",
            "LR: 0.0004096445538974574\n",
            "Train loss: 2.2183685302734375\n",
            "\n",
            "Time (s): 0.5137195587158203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 120 / 480\n",
            "LR: 0.00040962695710396586\n",
            "Train loss: 2.240142345428467\n",
            "\n",
            "Time (s): 0.5125317573547363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 121 / 480\n",
            "LR: 0.00040960936257795617\n",
            "Train loss: 2.0761935710906982\n",
            "\n",
            "Time (s): 0.5169820785522461\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 122 / 480\n",
            "LR: 0.0004095917703189416\n",
            "Train loss: 2.0478198528289795\n",
            "\n",
            "Time (s): 0.5250911712646484\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 123 / 480\n",
            "LR: 0.00040957418032643516\n",
            "Train loss: 2.0639798641204834\n",
            "\n",
            "Time (s): 0.5182957649230957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 124 / 480\n",
            "LR: 0.00040955659259995044\n",
            "Train loss: 2.1610679626464844\n",
            "\n",
            "Time (s): 0.5083644390106201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 125 / 480\n",
            "LR: 0.00040953900713900065\n",
            "Train loss: 2.0782556533813477\n",
            "\n",
            "Time (s): 0.5073809623718262\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 126 / 480\n",
            "LR: 0.00040952142394309963\n",
            "Train loss: 2.1683924198150635\n",
            "\n",
            "Time (s): 0.5160677433013916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 127 / 480\n",
            "LR: 0.00040950384301176123\n",
            "Train loss: 1.9383180141448975\n",
            "\n",
            "Time (s): 0.5056004524230957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 128 / 480\n",
            "LR: 0.0004094862643444993\n",
            "Train loss: 2.1446456909179688\n",
            "\n",
            "Time (s): 0.5083391666412354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 129 / 480\n",
            "LR: 0.0004094686879408279\n",
            "Train loss: 2.15629506111145\n",
            "\n",
            "Time (s): 0.5062129497528076\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 130 / 480\n",
            "LR: 0.00040945111380026144\n",
            "Train loss: 2.3858582973480225\n",
            "\n",
            "Time (s): 0.5061941146850586\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 131 / 480\n",
            "LR: 0.00040943354192231416\n",
            "Train loss: 2.448373317718506\n",
            "\n",
            "Time (s): 0.5084035396575928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 132 / 480\n",
            "LR: 0.0004094159723065006\n",
            "Train loss: 2.0526952743530273\n",
            "\n",
            "Time (s): 0.506056547164917\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 133 / 480\n",
            "LR: 0.0004093984049523355\n",
            "Train loss: 2.1278469562530518\n",
            "\n",
            "Time (s): 0.5075268745422363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 134 / 480\n",
            "LR: 0.00040938083985933365\n",
            "Train loss: 2.2472431659698486\n",
            "\n",
            "Time (s): 0.5080726146697998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 135 / 480\n",
            "LR: 0.00040936327702701005\n",
            "Train loss: 2.3700320720672607\n",
            "\n",
            "Time (s): 0.5046374797821045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 136 / 480\n",
            "LR: 0.00040934571645487967\n",
            "Train loss: 2.1214802265167236\n",
            "\n",
            "Time (s): 0.5070385932922363\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 137 / 480\n",
            "LR: 0.000409328158142458\n",
            "Train loss: 2.320363998413086\n",
            "\n",
            "Time (s): 0.5144813060760498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 138 / 480\n",
            "LR: 0.00040931060208926036\n",
            "Train loss: 2.273594379425049\n",
            "\n",
            "Time (s): 0.5106291770935059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 139 / 480\n",
            "LR: 0.0004092930482948022\n",
            "Train loss: 2.027268171310425\n",
            "\n",
            "Time (s): 0.5072665214538574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 140 / 480\n",
            "LR: 0.00040927549675859933\n",
            "Train loss: 2.374516010284424\n",
            "\n",
            "Time (s): 0.5086445808410645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 141 / 480\n",
            "LR: 0.0004092579474801675\n",
            "Train loss: 2.10038161277771\n",
            "\n",
            "Time (s): 0.50823974609375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 142 / 480\n",
            "LR: 0.0004092404004590229\n",
            "Train loss: 2.2027904987335205\n",
            "\n",
            "Time (s): 0.516089677810669\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 143 / 480\n",
            "LR: 0.00040922285569468134\n",
            "Train loss: 1.9260233640670776\n",
            "\n",
            "Time (s): 0.5139632225036621\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 144 / 480\n",
            "LR: 0.0004092053131866594\n",
            "Train loss: 2.0175013542175293\n",
            "\n",
            "Time (s): 0.5220584869384766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 145 / 480\n",
            "LR: 0.00040918777293447335\n",
            "Train loss: 2.431662082672119\n",
            "\n",
            "Time (s): 0.5116097927093506\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 146 / 480\n",
            "LR: 0.0004091702349376398\n",
            "Train loss: 2.154888153076172\n",
            "\n",
            "Time (s): 0.5200302600860596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 147 / 480\n",
            "LR: 0.0004091526991956754\n",
            "Train loss: 2.156174659729004\n",
            "\n",
            "Time (s): 0.5331697463989258\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 148 / 480\n",
            "LR: 0.00040913516570809707\n",
            "Train loss: 2.25480318069458\n",
            "\n",
            "Time (s): 0.5194923877716064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 149 / 480\n",
            "LR: 0.00040911763447442186\n",
            "Train loss: 2.1671268939971924\n",
            "\n",
            "Time (s): 0.5238707065582275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 150 / 480\n",
            "LR: 0.00040910010549416687\n",
            "Train loss: 2.209646463394165\n",
            "\n",
            "Time (s): 0.514695405960083\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 151 / 480\n",
            "LR: 0.00040908257876684934\n",
            "Train loss: 2.1642658710479736\n",
            "\n",
            "Time (s): 0.5129482746124268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 152 / 480\n",
            "LR: 0.0004090650542919868\n",
            "Train loss: 2.0733091831207275\n",
            "\n",
            "Time (s): 0.5130424499511719\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 153 / 480\n",
            "LR: 0.0004090475320690967\n",
            "Train loss: 2.3261587619781494\n",
            "\n",
            "Time (s): 0.514509916305542\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 154 / 480\n",
            "LR: 0.00040903001209769693\n",
            "Train loss: 2.2855610847473145\n",
            "\n",
            "Time (s): 0.5098171234130859\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 155 / 480\n",
            "LR: 0.00040901249437730525\n",
            "Train loss: 2.1868231296539307\n",
            "\n",
            "Time (s): 0.5089333057403564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 156 / 480\n",
            "LR: 0.00040899497890743974\n",
            "Train loss: 2.4410884380340576\n",
            "\n",
            "Time (s): 0.5102739334106445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 157 / 480\n",
            "LR: 0.0004089774656876185\n",
            "Train loss: 2.1455066204071045\n",
            "\n",
            "Time (s): 0.5086367130279541\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 158 / 480\n",
            "LR: 0.00040895995471735983\n",
            "Train loss: 2.1137640476226807\n",
            "\n",
            "Time (s): 0.5089218616485596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 159 / 480\n",
            "LR: 0.0004089424459961823\n",
            "Train loss: 2.26592755317688\n",
            "\n",
            "Time (s): 0.5041520595550537\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 160 / 480\n",
            "LR: 0.00040892493952360444\n",
            "Train loss: 2.1649391651153564\n",
            "\n",
            "Time (s): 0.5073230266571045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 161 / 480\n",
            "LR: 0.0004089074352991449\n",
            "Train loss: 2.328589916229248\n",
            "\n",
            "Time (s): 0.5050146579742432\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 162 / 480\n",
            "LR: 0.0004088899333223226\n",
            "Train loss: 2.0511863231658936\n",
            "\n",
            "Time (s): 0.5109426975250244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 163 / 480\n",
            "LR: 0.0004088724335926567\n",
            "Train loss: 1.9930495023727417\n",
            "\n",
            "Time (s): 0.5107522010803223\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 164 / 480\n",
            "LR: 0.00040885493610966624\n",
            "Train loss: 2.2291476726531982\n",
            "\n",
            "Time (s): 0.5075855255126953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 165 / 480\n",
            "LR: 0.00040883744087287055\n",
            "Train loss: 2.12331485748291\n",
            "\n",
            "Time (s): 0.5071797370910645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 166 / 480\n",
            "LR: 0.0004088199478817891\n",
            "Train loss: 2.3200438022613525\n",
            "\n",
            "Time (s): 0.5110220909118652\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 167 / 480\n",
            "LR: 0.0004088024571359415\n",
            "Train loss: 2.2111592292785645\n",
            "\n",
            "Time (s): 0.5126211643218994\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 168 / 480\n",
            "LR: 0.00040878496863484755\n",
            "Train loss: 2.267611026763916\n",
            "\n",
            "Time (s): 0.5060765743255615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 169 / 480\n",
            "LR: 0.000408767482378027\n",
            "Train loss: 2.4423372745513916\n",
            "\n",
            "Time (s): 0.5130276679992676\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 170 / 480\n",
            "LR: 0.000408749998365\n",
            "Train loss: 2.1564440727233887\n",
            "\n",
            "Time (s): 0.5234203338623047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 171 / 480\n",
            "LR: 0.0004087325165952866\n",
            "Train loss: 2.442836284637451\n",
            "\n",
            "Time (s): 0.5214591026306152\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 172 / 480\n",
            "LR: 0.00040871503706840735\n",
            "Train loss: 2.31427264213562\n",
            "\n",
            "Time (s): 0.5219933986663818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 173 / 480\n",
            "LR: 0.0004086975597838825\n",
            "Train loss: 2.5779855251312256\n",
            "\n",
            "Time (s): 0.5127148628234863\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 174 / 480\n",
            "LR: 0.0004086800847412328\n",
            "Train loss: 2.301687002182007\n",
            "\n",
            "Time (s): 0.5116245746612549\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 175 / 480\n",
            "LR: 0.0004086626119399789\n",
            "Train loss: 2.3541548252105713\n",
            "\n",
            "Time (s): 0.5143311023712158\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 176 / 480\n",
            "LR: 0.00040864514137964173\n",
            "Train loss: 2.1148629188537598\n",
            "\n",
            "Time (s): 0.5115761756896973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 177 / 480\n",
            "LR: 0.00040862767305974233\n",
            "Train loss: 2.4418883323669434\n",
            "\n",
            "Time (s): 0.5115325450897217\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 178 / 480\n",
            "LR: 0.0004086102069798019\n",
            "Train loss: 2.1719839572906494\n",
            "\n",
            "Time (s): 0.5073184967041016\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 179 / 480\n",
            "LR: 0.0004085927431393417\n",
            "Train loss: 2.2376787662506104\n",
            "\n",
            "Time (s): 0.5029404163360596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 180 / 480\n",
            "LR: 0.0004085752815378834\n",
            "Train loss: 1.9645400047302246\n",
            "\n",
            "Time (s): 0.5143430233001709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 181 / 480\n",
            "LR: 0.0004085578221749483\n",
            "Train loss: 1.926819086074829\n",
            "\n",
            "Time (s): 0.5132961273193359\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 182 / 480\n",
            "LR: 0.00040854036505005837\n",
            "Train loss: 2.2425856590270996\n",
            "\n",
            "Time (s): 0.5086660385131836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 183 / 480\n",
            "LR: 0.0004085229101627355\n",
            "Train loss: 2.3636929988861084\n",
            "\n",
            "Time (s): 0.508563756942749\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 184 / 480\n",
            "LR: 0.00040850545751250155\n",
            "Train loss: 2.2585864067077637\n",
            "\n",
            "Time (s): 0.5089139938354492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 185 / 480\n",
            "LR: 0.00040848800709887903\n",
            "Train loss: 2.2153193950653076\n",
            "\n",
            "Time (s): 0.5079410076141357\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 186 / 480\n",
            "LR: 0.00040847055892138993\n",
            "Train loss: 2.2304599285125732\n",
            "\n",
            "Time (s): 0.5158166885375977\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 187 / 480\n",
            "LR: 0.00040845311297955684\n",
            "Train loss: 2.253319501876831\n",
            "\n",
            "Time (s): 0.5134406089782715\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 188 / 480\n",
            "LR: 0.0004084356692729025\n",
            "Train loss: 2.193028450012207\n",
            "\n",
            "Time (s): 0.5156002044677734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 189 / 480\n",
            "LR: 0.00040841822780094956\n",
            "Train loss: 1.99810791015625\n",
            "\n",
            "Time (s): 0.5106048583984375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 190 / 480\n",
            "LR: 0.0004084007885632208\n",
            "Train loss: 2.4299328327178955\n",
            "\n",
            "Time (s): 0.5045228004455566\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 191 / 480\n",
            "LR: 0.0004083833515592394\n",
            "Train loss: 1.9862170219421387\n",
            "\n",
            "Time (s): 0.5102107524871826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 192 / 480\n",
            "LR: 0.00040836591678852866\n",
            "Train loss: 2.0030393600463867\n",
            "\n",
            "Time (s): 0.5139579772949219\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 193 / 480\n",
            "LR: 0.0004083484842506116\n",
            "Train loss: 2.182223320007324\n",
            "\n",
            "Time (s): 0.5109865665435791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 194 / 480\n",
            "LR: 0.00040833105394501193\n",
            "Train loss: 2.09726881980896\n",
            "\n",
            "Time (s): 0.5106048583984375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 195 / 480\n",
            "LR: 0.00040831362587125314\n",
            "Train loss: 2.0371291637420654\n",
            "\n",
            "Time (s): 0.5038290023803711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 196 / 480\n",
            "LR: 0.0004082962000288591\n",
            "Train loss: 2.1866891384124756\n",
            "\n",
            "Time (s): 0.511786937713623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 197 / 480\n",
            "LR: 0.0004082787764173535\n",
            "Train loss: 2.1661133766174316\n",
            "\n",
            "Time (s): 0.5241789817810059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 198 / 480\n",
            "LR: 0.0004082613550362607\n",
            "Train loss: 2.0200207233428955\n",
            "\n",
            "Time (s): 0.514887809753418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 199 / 480\n",
            "LR: 0.0004082439358851045\n",
            "Train loss: 2.4577934741973877\n",
            "\n",
            "Time (s): 0.5238666534423828\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 200 / 480\n",
            "LR: 0.0004082265189634095\n",
            "Train loss: 2.064664125442505\n",
            "\n",
            "Time (s): 0.523223876953125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 201 / 480\n",
            "LR: 0.00040820910427069997\n",
            "Train loss: 2.047451972961426\n",
            "\n",
            "Time (s): 0.5156114101409912\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 202 / 480\n",
            "LR: 0.00040819169180650067\n",
            "Train loss: 2.355865001678467\n",
            "\n",
            "Time (s): 0.5104491710662842\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 203 / 480\n",
            "LR: 0.0004081742815703363\n",
            "Train loss: 2.087956190109253\n",
            "\n",
            "Time (s): 0.5103943347930908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 204 / 480\n",
            "LR: 0.0004081568735617317\n",
            "Train loss: 2.186551570892334\n",
            "\n",
            "Time (s): 0.5125422477722168\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 205 / 480\n",
            "LR: 0.00040813946778021194\n",
            "Train loss: 1.981831669807434\n",
            "\n",
            "Time (s): 0.5106174945831299\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 206 / 480\n",
            "LR: 0.0004081220642253023\n",
            "Train loss: 2.329498052597046\n",
            "\n",
            "Time (s): 0.5077979564666748\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 207 / 480\n",
            "LR: 0.0004081046628965278\n",
            "Train loss: 2.0051820278167725\n",
            "\n",
            "Time (s): 0.5067298412322998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 208 / 480\n",
            "LR: 0.00040808726379341415\n",
            "Train loss: 2.39890718460083\n",
            "\n",
            "Time (s): 0.507504940032959\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 209 / 480\n",
            "LR: 0.00040806986691548693\n",
            "Train loss: 2.36562442779541\n",
            "\n",
            "Time (s): 0.5068051815032959\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 210 / 480\n",
            "LR: 0.0004080524722622717\n",
            "Train loss: 2.1288065910339355\n",
            "\n",
            "Time (s): 0.5091345310211182\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 211 / 480\n",
            "LR: 0.00040803507983329455\n",
            "Train loss: 1.7710704803466797\n",
            "\n",
            "Time (s): 0.5158615112304688\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 212 / 480\n",
            "LR: 0.00040801768962808147\n",
            "Train loss: 2.2516250610351562\n",
            "\n",
            "Time (s): 0.512211799621582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 213 / 480\n",
            "LR: 0.0004080003016461585\n",
            "Train loss: 2.31030011177063\n",
            "\n",
            "Time (s): 0.5071101188659668\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 214 / 480\n",
            "LR: 0.00040798291588705195\n",
            "Train loss: 2.3265535831451416\n",
            "\n",
            "Time (s): 0.5101804733276367\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 215 / 480\n",
            "LR: 0.00040796553235028846\n",
            "Train loss: 2.3229994773864746\n",
            "\n",
            "Time (s): 0.5043156147003174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 216 / 480\n",
            "LR: 0.0004079481510353944\n",
            "Train loss: 2.2228095531463623\n",
            "\n",
            "Time (s): 0.5121653079986572\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 217 / 480\n",
            "LR: 0.00040793077194189667\n",
            "Train loss: 2.2288877964019775\n",
            "\n",
            "Time (s): 0.5057623386383057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 218 / 480\n",
            "LR: 0.00040791339506932197\n",
            "Train loss: 2.1813437938690186\n",
            "\n",
            "Time (s): 0.5115487575531006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 219 / 480\n",
            "LR: 0.0004078960204171974\n",
            "Train loss: 2.417647123336792\n",
            "\n",
            "Time (s): 0.5106770992279053\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 220 / 480\n",
            "LR: 0.0004078786479850501\n",
            "Train loss: 2.265869140625\n",
            "\n",
            "Time (s): 0.5181400775909424\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 221 / 480\n",
            "LR: 0.0004078612777724074\n",
            "Train loss: 2.2800700664520264\n",
            "\n",
            "Time (s): 0.5116839408874512\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 222 / 480\n",
            "LR: 0.00040784390977879664\n",
            "Train loss: 2.144948720932007\n",
            "\n",
            "Time (s): 0.5091893672943115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 223 / 480\n",
            "LR: 0.0004078265440037455\n",
            "Train loss: 2.243816375732422\n",
            "\n",
            "Time (s): 0.5293169021606445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 224 / 480\n",
            "LR: 0.0004078091804467816\n",
            "Train loss: 1.9157254695892334\n",
            "\n",
            "Time (s): 0.5245635509490967\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 225 / 480\n",
            "LR: 0.0004077918191074329\n",
            "Train loss: 1.994867205619812\n",
            "\n",
            "Time (s): 0.5137076377868652\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 226 / 480\n",
            "LR: 0.0004077744599852274\n",
            "Train loss: 2.3103888034820557\n",
            "\n",
            "Time (s): 0.5163455009460449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 227 / 480\n",
            "LR: 0.0004077571030796931\n",
            "Train loss: 2.2177412509918213\n",
            "\n",
            "Time (s): 0.5270836353302002\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 228 / 480\n",
            "LR: 0.0004077397483903583\n",
            "Train loss: 2.3317039012908936\n",
            "\n",
            "Time (s): 0.5248889923095703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 229 / 480\n",
            "LR: 0.00040772239591675154\n",
            "Train loss: 2.074439287185669\n",
            "\n",
            "Time (s): 0.5238265991210938\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 230 / 480\n",
            "LR: 0.00040770504565840134\n",
            "Train loss: 2.017866373062134\n",
            "\n",
            "Time (s): 0.5101509094238281\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 231 / 480\n",
            "LR: 0.00040768769761483634\n",
            "Train loss: 2.3071799278259277\n",
            "\n",
            "Time (s): 0.5104131698608398\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 232 / 480\n",
            "LR: 0.0004076703517855855\n",
            "Train loss: 2.188730239868164\n",
            "\n",
            "Time (s): 0.5130739212036133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 233 / 480\n",
            "LR: 0.0004076530081701775\n",
            "Train loss: 2.2596676349639893\n",
            "\n",
            "Time (s): 0.5126721858978271\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 234 / 480\n",
            "LR: 0.0004076356667681418\n",
            "Train loss: 2.165788412094116\n",
            "\n",
            "Time (s): 0.5328845977783203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 235 / 480\n",
            "LR: 0.00040761832757900754\n",
            "Train loss: 2.110154867172241\n",
            "\n",
            "Time (s): 0.5117635726928711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 236 / 480\n",
            "LR: 0.00040760099060230406\n",
            "Train loss: 2.026528835296631\n",
            "\n",
            "Time (s): 0.5117621421813965\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 237 / 480\n",
            "LR: 0.00040758365583756095\n",
            "Train loss: 2.2110812664031982\n",
            "\n",
            "Time (s): 0.5202834606170654\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 238 / 480\n",
            "LR: 0.00040756632328430795\n",
            "Train loss: 2.1036338806152344\n",
            "\n",
            "Time (s): 0.5078742504119873\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 239 / 480\n",
            "LR: 0.00040754899294207474\n",
            "Train loss: 2.1670403480529785\n",
            "\n",
            "Time (s): 0.5110373497009277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 240 / 480\n",
            "LR: 0.00040753166481039146\n",
            "Train loss: 2.3097198009490967\n",
            "\n",
            "Time (s): 0.5111408233642578\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 241 / 480\n",
            "LR: 0.000407514338888788\n",
            "Train loss: 2.4234113693237305\n",
            "\n",
            "Time (s): 0.5090491771697998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 242 / 480\n",
            "LR: 0.0004074970151767948\n",
            "Train loss: 2.1655354499816895\n",
            "\n",
            "Time (s): 0.5065488815307617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 243 / 480\n",
            "LR: 0.0004074796936739421\n",
            "Train loss: 2.172866106033325\n",
            "\n",
            "Time (s): 0.5113673210144043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 244 / 480\n",
            "LR: 0.0004074623743797605\n",
            "Train loss: 2.0562329292297363\n",
            "\n",
            "Time (s): 0.508500337600708\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 245 / 480\n",
            "LR: 0.00040744505729378065\n",
            "Train loss: 2.1873860359191895\n",
            "\n",
            "Time (s): 0.507603645324707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 246 / 480\n",
            "LR: 0.0004074277424155332\n",
            "Train loss: 2.298705816268921\n",
            "\n",
            "Time (s): 0.5066671371459961\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 247 / 480\n",
            "LR: 0.00040741042974454933\n",
            "Train loss: 1.7923482656478882\n",
            "\n",
            "Time (s): 0.5107805728912354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 248 / 480\n",
            "LR: 0.00040739311928035993\n",
            "Train loss: 2.228712320327759\n",
            "\n",
            "Time (s): 0.508310079574585\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 249 / 480\n",
            "LR: 0.0004073758110224964\n",
            "Train loss: 1.9831336736679077\n",
            "\n",
            "Time (s): 0.514916181564331\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 250 / 480\n",
            "LR: 0.00040735850497048993\n",
            "Train loss: 2.0486626625061035\n",
            "\n",
            "Time (s): 0.5166456699371338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 251 / 480\n",
            "LR: 0.0004073412011238721\n",
            "Train loss: 2.1191020011901855\n",
            "\n",
            "Time (s): 0.5213572978973389\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 252 / 480\n",
            "LR: 0.00040732389948217447\n",
            "Train loss: 2.2823526859283447\n",
            "\n",
            "Time (s): 0.5128293037414551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 253 / 480\n",
            "LR: 0.00040730660004492886\n",
            "Train loss: 1.9672669172286987\n",
            "\n",
            "Time (s): 0.522254467010498\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 254 / 480\n",
            "LR: 0.00040728930281166726\n",
            "Train loss: 2.193758010864258\n",
            "\n",
            "Time (s): 0.5194342136383057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 255 / 480\n",
            "LR: 0.0004072720077819216\n",
            "Train loss: 2.3091866970062256\n",
            "\n",
            "Time (s): 0.5188107490539551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 256 / 480\n",
            "LR: 0.0004072547149552241\n",
            "Train loss: 2.1477913856506348\n",
            "\n",
            "Time (s): 0.5090343952178955\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 257 / 480\n",
            "LR: 0.00040723742433110716\n",
            "Train loss: 2.1835777759552\n",
            "\n",
            "Time (s): 0.506962776184082\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 258 / 480\n",
            "LR: 0.0004072201359091032\n",
            "Train loss: 2.322303295135498\n",
            "\n",
            "Time (s): 0.5032570362091064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 259 / 480\n",
            "LR: 0.00040720284968874483\n",
            "Train loss: 2.4435839653015137\n",
            "\n",
            "Time (s): 0.5039451122283936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 260 / 480\n",
            "LR: 0.0004071855656695648\n",
            "Train loss: 2.281148672103882\n",
            "\n",
            "Time (s): 0.5059070587158203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 261 / 480\n",
            "LR: 0.0004071682838510959\n",
            "Train loss: 2.1942477226257324\n",
            "\n",
            "Time (s): 0.5094408988952637\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 262 / 480\n",
            "LR: 0.00040715100423287145\n",
            "Train loss: 1.8664599657058716\n",
            "\n",
            "Time (s): 0.5075860023498535\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 263 / 480\n",
            "LR: 0.00040713372681442424\n",
            "Train loss: 2.390608787536621\n",
            "\n",
            "Time (s): 0.5043046474456787\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 264 / 480\n",
            "LR: 0.00040711645159528787\n",
            "Train loss: 2.1524839401245117\n",
            "\n",
            "Time (s): 0.5105431079864502\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 265 / 480\n",
            "LR: 0.00040709917857499557\n",
            "Train loss: 2.2033534049987793\n",
            "\n",
            "Time (s): 0.510530948638916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 266 / 480\n",
            "LR: 0.00040708190775308104\n",
            "Train loss: 2.078650712966919\n",
            "\n",
            "Time (s): 0.5029325485229492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 267 / 480\n",
            "LR: 0.00040706463912907795\n",
            "Train loss: 2.2126824855804443\n",
            "\n",
            "Time (s): 0.5098464488983154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 268 / 480\n",
            "LR: 0.0004070473727025202\n",
            "Train loss: 2.1406238079071045\n",
            "\n",
            "Time (s): 0.5088367462158203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 269 / 480\n",
            "LR: 0.00040703010847294174\n",
            "Train loss: 1.9656609296798706\n",
            "\n",
            "Time (s): 0.5101175308227539\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 270 / 480\n",
            "LR: 0.0004070128464398768\n",
            "Train loss: 2.2926137447357178\n",
            "\n",
            "Time (s): 0.5186600685119629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 271 / 480\n",
            "LR: 0.00040699558660285955\n",
            "Train loss: 2.1681649684906006\n",
            "\n",
            "Time (s): 0.5120706558227539\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 272 / 480\n",
            "LR: 0.0004069783289614244\n",
            "Train loss: 2.211571455001831\n",
            "\n",
            "Time (s): 0.5119495391845703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 273 / 480\n",
            "LR: 0.0004069610735151059\n",
            "Train loss: 1.9827847480773926\n",
            "\n",
            "Time (s): 0.5121281147003174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 274 / 480\n",
            "LR: 0.00040694382026343877\n",
            "Train loss: 2.535182237625122\n",
            "\n",
            "Time (s): 0.5070436000823975\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 275 / 480\n",
            "LR: 0.0004069265692059578\n",
            "Train loss: 2.0949182510375977\n",
            "\n",
            "Time (s): 0.5100393295288086\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 276 / 480\n",
            "LR: 0.0004069093203421981\n",
            "Train loss: 2.07253098487854\n",
            "\n",
            "Time (s): 0.5152757167816162\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 277 / 480\n",
            "LR: 0.0004068920736716945\n",
            "Train loss: 2.0652918815612793\n",
            "\n",
            "Time (s): 0.5097873210906982\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 278 / 480\n",
            "LR: 0.0004068748291939825\n",
            "Train loss: 2.091625452041626\n",
            "\n",
            "Time (s): 0.522219181060791\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 279 / 480\n",
            "LR: 0.00040685758690859735\n",
            "Train loss: 2.4857215881347656\n",
            "\n",
            "Time (s): 0.5188796520233154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 280 / 480\n",
            "LR: 0.00040684034681507454\n",
            "Train loss: 2.433530569076538\n",
            "\n",
            "Time (s): 0.5052406787872314\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 281 / 480\n",
            "LR: 0.0004068231089129498\n",
            "Train loss: 1.9703067541122437\n",
            "\n",
            "Time (s): 0.518498420715332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 282 / 480\n",
            "LR: 0.00040680587320175883\n",
            "Train loss: 2.437230110168457\n",
            "\n",
            "Time (s): 0.5141000747680664\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 283 / 480\n",
            "LR: 0.0004067886396810377\n",
            "Train loss: 2.0848093032836914\n",
            "\n",
            "Time (s): 0.5062246322631836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 284 / 480\n",
            "LR: 0.00040677140835032225\n",
            "Train loss: 2.1274750232696533\n",
            "\n",
            "Time (s): 0.5062079429626465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 285 / 480\n",
            "LR: 0.0004067541792091488\n",
            "Train loss: 2.046351432800293\n",
            "\n",
            "Time (s): 0.5040016174316406\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 286 / 480\n",
            "LR: 0.0004067369522570539\n",
            "Train loss: 1.8507124185562134\n",
            "\n",
            "Time (s): 0.5057966709136963\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 287 / 480\n",
            "LR: 0.00040671972749357373\n",
            "Train loss: 2.085606813430786\n",
            "\n",
            "Time (s): 0.511908769607544\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 288 / 480\n",
            "LR: 0.0004067025049182449\n",
            "Train loss: 2.1938116550445557\n",
            "\n",
            "Time (s): 0.5108132362365723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 289 / 480\n",
            "LR: 0.0004066852845306044\n",
            "Train loss: 2.045632839202881\n",
            "\n",
            "Time (s): 0.5062687397003174\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 290 / 480\n",
            "LR: 0.0004066680663301889\n",
            "Train loss: 2.088167428970337\n",
            "\n",
            "Time (s): 0.5133230686187744\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 291 / 480\n",
            "LR: 0.00040665085031653565\n",
            "Train loss: 2.2637999057769775\n",
            "\n",
            "Time (s): 0.5071849822998047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 292 / 480\n",
            "LR: 0.0004066336364891815\n",
            "Train loss: 1.765307068824768\n",
            "\n",
            "Time (s): 0.5045185089111328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 293 / 480\n",
            "LR: 0.000406616424847664\n",
            "Train loss: 2.0442004203796387\n",
            "\n",
            "Time (s): 0.5078651905059814\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 294 / 480\n",
            "LR: 0.0004065992153915206\n",
            "Train loss: 2.365929365158081\n",
            "\n",
            "Time (s): 0.5074851512908936\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 295 / 480\n",
            "LR: 0.0004065820081202887\n",
            "Train loss: 1.9781765937805176\n",
            "\n",
            "Time (s): 0.5152039527893066\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 296 / 480\n",
            "LR: 0.0004065648030335061\n",
            "Train loss: 2.2520434856414795\n",
            "\n",
            "Time (s): 0.5120172500610352\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 297 / 480\n",
            "LR: 0.0004065476001307107\n",
            "Train loss: 2.3807501792907715\n",
            "\n",
            "Time (s): 0.5097568035125732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 298 / 480\n",
            "LR: 0.0004065303994114404\n",
            "Train loss: 2.0548386573791504\n",
            "\n",
            "Time (s): 0.5080039501190186\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 299 / 480\n",
            "LR: 0.0004065132008752334\n",
            "Train loss: 2.102780342102051\n",
            "\n",
            "Time (s): 0.5085914134979248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 300 / 480\n",
            "LR: 0.0004064960045216279\n",
            "Train loss: 2.174915313720703\n",
            "\n",
            "Time (s): 0.5083873271942139\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 301 / 480\n",
            "LR: 0.0004064788103501624\n",
            "Train loss: 1.9712574481964111\n",
            "\n",
            "Time (s): 0.5048816204071045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 302 / 480\n",
            "LR: 0.0004064616183603752\n",
            "Train loss: 2.131685733795166\n",
            "\n",
            "Time (s): 0.510631799697876\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 303 / 480\n",
            "LR: 0.0004064444285518052\n",
            "Train loss: 2.0046041011810303\n",
            "\n",
            "Time (s): 0.5132725238800049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 304 / 480\n",
            "LR: 0.0004064272409239911\n",
            "Train loss: 2.000521659851074\n",
            "\n",
            "Time (s): 0.5148110389709473\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 305 / 480\n",
            "LR: 0.00040641005547647195\n",
            "Train loss: 2.1133713722229004\n",
            "\n",
            "Time (s): 0.5201711654663086\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 306 / 480\n",
            "LR: 0.00040639287220878664\n",
            "Train loss: 2.401738166809082\n",
            "\n",
            "Time (s): 0.5150034427642822\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 307 / 480\n",
            "LR: 0.00040637569112047454\n",
            "Train loss: 1.9429192543029785\n",
            "\n",
            "Time (s): 0.5263926982879639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 308 / 480\n",
            "LR: 0.00040635851221107493\n",
            "Train loss: 2.0386829376220703\n",
            "\n",
            "Time (s): 0.5244534015655518\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 309 / 480\n",
            "LR: 0.00040634133548012735\n",
            "Train loss: 2.213710069656372\n",
            "\n",
            "Time (s): 0.5183424949645996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 310 / 480\n",
            "LR: 0.00040632416092717144\n",
            "Train loss: 2.183920383453369\n",
            "\n",
            "Time (s): 0.5054168701171875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 311 / 480\n",
            "LR: 0.0004063069885517468\n",
            "Train loss: 2.16499400138855\n",
            "\n",
            "Time (s): 0.5120458602905273\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 312 / 480\n",
            "LR: 0.0004062898183533935\n",
            "Train loss: 2.156256914138794\n",
            "\n",
            "Time (s): 0.5184524059295654\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 313 / 480\n",
            "LR: 0.00040627265033165154\n",
            "Train loss: 2.0593976974487305\n",
            "\n",
            "Time (s): 0.5172765254974365\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 314 / 480\n",
            "LR: 0.00040625548448606103\n",
            "Train loss: 2.3244264125823975\n",
            "\n",
            "Time (s): 0.5130445957183838\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 315 / 480\n",
            "LR: 0.00040623832081616233\n",
            "Train loss: 2.1413064002990723\n",
            "\n",
            "Time (s): 0.5063748359680176\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 316 / 480\n",
            "LR: 0.0004062211593214959\n",
            "Train loss: 2.0128161907196045\n",
            "\n",
            "Time (s): 0.5061419010162354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 317 / 480\n",
            "LR: 0.0004062040000016022\n",
            "Train loss: 2.261739492416382\n",
            "\n",
            "Time (s): 0.5128388404846191\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 318 / 480\n",
            "LR: 0.00040618684285602207\n",
            "Train loss: 1.9352459907531738\n",
            "\n",
            "Time (s): 0.5175948143005371\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 319 / 480\n",
            "LR: 0.0004061696878842963\n",
            "Train loss: 1.8800609111785889\n",
            "\n",
            "Time (s): 0.5091907978057861\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 320 / 480\n",
            "LR: 0.00040615253508596584\n",
            "Train loss: 2.0806915760040283\n",
            "\n",
            "Time (s): 0.5078036785125732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 321 / 480\n",
            "LR: 0.0004061353844605719\n",
            "Train loss: 2.235032320022583\n",
            "\n",
            "Time (s): 0.5085306167602539\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 322 / 480\n",
            "LR: 0.00040611823600765566\n",
            "Train loss: 2.412036180496216\n",
            "\n",
            "Time (s): 0.508857250213623\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 323 / 480\n",
            "LR: 0.00040610108972675854\n",
            "Train loss: 2.2843401432037354\n",
            "\n",
            "Time (s): 0.5138986110687256\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 324 / 480\n",
            "LR: 0.0004060839456174221\n",
            "Train loss: 2.51434063911438\n",
            "\n",
            "Time (s): 0.5116112232208252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 325 / 480\n",
            "LR: 0.0004060668036791879\n",
            "Train loss: 2.3863794803619385\n",
            "\n",
            "Time (s): 0.5065672397613525\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 326 / 480\n",
            "LR: 0.00040604966391159786\n",
            "Train loss: 2.2218117713928223\n",
            "\n",
            "Time (s): 0.5069169998168945\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 327 / 480\n",
            "LR: 0.00040603252631419385\n",
            "Train loss: 2.2554335594177246\n",
            "\n",
            "Time (s): 0.5087051391601562\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 328 / 480\n",
            "LR: 0.0004060153908865179\n",
            "Train loss: 2.090963125228882\n",
            "\n",
            "Time (s): 0.5060105323791504\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 329 / 480\n",
            "LR: 0.0004059982576281123\n",
            "Train loss: 1.9817008972167969\n",
            "\n",
            "Time (s): 0.5171046257019043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 330 / 480\n",
            "LR: 0.0004059811265385193\n",
            "Train loss: 2.119697332382202\n",
            "\n",
            "Time (s): 0.5196740627288818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 331 / 480\n",
            "LR: 0.00040596399761728144\n",
            "Train loss: 2.3082830905914307\n",
            "\n",
            "Time (s): 0.5124070644378662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 332 / 480\n",
            "LR: 0.0004059468708639413\n",
            "Train loss: 2.37034273147583\n",
            "\n",
            "Time (s): 0.5175013542175293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 333 / 480\n",
            "LR: 0.00040592974627804166\n",
            "Train loss: 2.348461389541626\n",
            "\n",
            "Time (s): 0.5162765979766846\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 334 / 480\n",
            "LR: 0.0004059126238591253\n",
            "Train loss: 2.1343984603881836\n",
            "\n",
            "Time (s): 0.5178713798522949\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 335 / 480\n",
            "LR: 0.0004058955036067353\n",
            "Train loss: 2.3473072052001953\n",
            "\n",
            "Time (s): 0.5101656913757324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 336 / 480\n",
            "LR: 0.0004058783855204149\n",
            "Train loss: 2.1915948390960693\n",
            "\n",
            "Time (s): 0.5127675533294678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 337 / 480\n",
            "LR: 0.00040586126959970723\n",
            "Train loss: 2.088475465774536\n",
            "\n",
            "Time (s): 0.5130045413970947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 338 / 480\n",
            "LR: 0.0004058441558441558\n",
            "Train loss: 2.0637035369873047\n",
            "\n",
            "Time (s): 0.5120408535003662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 339 / 480\n",
            "LR: 0.00040582704425330414\n",
            "Train loss: 1.8181339502334595\n",
            "\n",
            "Time (s): 0.509918212890625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 340 / 480\n",
            "LR: 0.0004058099348266959\n",
            "Train loss: 1.9666677713394165\n",
            "\n",
            "Time (s): 0.507335901260376\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 341 / 480\n",
            "LR: 0.000405792827563875\n",
            "Train loss: 1.9361517429351807\n",
            "\n",
            "Time (s): 0.512007474899292\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 342 / 480\n",
            "LR: 0.0004057757224643853\n",
            "Train loss: 2.446068286895752\n",
            "\n",
            "Time (s): 0.5141301155090332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 343 / 480\n",
            "LR: 0.0004057586195277709\n",
            "Train loss: 2.0897042751312256\n",
            "\n",
            "Time (s): 0.5120010375976562\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 344 / 480\n",
            "LR: 0.00040574151875357606\n",
            "Train loss: 2.120112419128418\n",
            "\n",
            "Time (s): 0.5136418342590332\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 345 / 480\n",
            "LR: 0.00040572442014134516\n",
            "Train loss: 2.290130376815796\n",
            "\n",
            "Time (s): 0.5079247951507568\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 346 / 480\n",
            "LR: 0.0004057073236906226\n",
            "Train loss: 2.162130355834961\n",
            "\n",
            "Time (s): 0.5134859085083008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 347 / 480\n",
            "LR: 0.0004056902294009531\n",
            "Train loss: 2.1802456378936768\n",
            "\n",
            "Time (s): 0.5182263851165771\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 348 / 480\n",
            "LR: 0.0004056731372718814\n",
            "Train loss: 2.130378007888794\n",
            "\n",
            "Time (s): 0.513420820236206\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 349 / 480\n",
            "LR: 0.00040565604730295247\n",
            "Train loss: 2.228753089904785\n",
            "\n",
            "Time (s): 0.5144050121307373\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 350 / 480\n",
            "LR: 0.0004056389594937112\n",
            "Train loss: 1.9054529666900635\n",
            "\n",
            "Time (s): 0.5164933204650879\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 351 / 480\n",
            "LR: 0.0004056218738437028\n",
            "Train loss: 2.1326708793640137\n",
            "\n",
            "Time (s): 0.518031120300293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 352 / 480\n",
            "LR: 0.00040560479035247265\n",
            "Train loss: 2.551056385040283\n",
            "\n",
            "Time (s): 0.509474515914917\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 353 / 480\n",
            "LR: 0.00040558770901956615\n",
            "Train loss: 2.228224754333496\n",
            "\n",
            "Time (s): 0.5072052478790283\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 354 / 480\n",
            "LR: 0.00040557062984452875\n",
            "Train loss: 1.7945176362991333\n",
            "\n",
            "Time (s): 0.5056304931640625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 355 / 480\n",
            "LR: 0.0004055535528269063\n",
            "Train loss: 2.263840436935425\n",
            "\n",
            "Time (s): 0.507256031036377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 356 / 480\n",
            "LR: 0.0004055364779662446\n",
            "Train loss: 2.6321218013763428\n",
            "\n",
            "Time (s): 0.5144727230072021\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 357 / 480\n",
            "LR: 0.0004055194052620896\n",
            "Train loss: 2.34234881401062\n",
            "\n",
            "Time (s): 0.5204989910125732\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 358 / 480\n",
            "LR: 0.00040550233471398745\n",
            "Train loss: 2.0439634323120117\n",
            "\n",
            "Time (s): 0.5223536491394043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 359 / 480\n",
            "LR: 0.00040548526632148426\n",
            "Train loss: 2.076746940612793\n",
            "\n",
            "Time (s): 0.5223195552825928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 360 / 480\n",
            "LR: 0.0004054682000841265\n",
            "Train loss: 2.2164154052734375\n",
            "\n",
            "Time (s): 0.512242317199707\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 361 / 480\n",
            "LR: 0.0004054511360014607\n",
            "Train loss: 2.10079026222229\n",
            "\n",
            "Time (s): 0.510042667388916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 362 / 480\n",
            "LR: 0.00040543407407303344\n",
            "Train loss: 2.3550708293914795\n",
            "\n",
            "Time (s): 0.5173187255859375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 363 / 480\n",
            "LR: 0.0004054170142983915\n",
            "Train loss: 1.9557021856307983\n",
            "\n",
            "Time (s): 0.5088541507720947\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 364 / 480\n",
            "LR: 0.0004053999566770818\n",
            "Train loss: 2.1810262203216553\n",
            "\n",
            "Time (s): 0.5080821514129639\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 365 / 480\n",
            "LR: 0.00040538290120865146\n",
            "Train loss: 2.0147509574890137\n",
            "\n",
            "Time (s): 0.5138869285583496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 366 / 480\n",
            "LR: 0.0004053658478926475\n",
            "Train loss: 2.202713966369629\n",
            "\n",
            "Time (s): 0.5086793899536133\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 367 / 480\n",
            "LR: 0.00040534879672861725\n",
            "Train loss: 2.4363820552825928\n",
            "\n",
            "Time (s): 0.5136284828186035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 368 / 480\n",
            "LR: 0.0004053317477161083\n",
            "Train loss: 2.0528712272644043\n",
            "\n",
            "Time (s): 0.5107338428497314\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 369 / 480\n",
            "LR: 0.00040531470085466807\n",
            "Train loss: 1.8683732748031616\n",
            "\n",
            "Time (s): 0.5123653411865234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 370 / 480\n",
            "LR: 0.0004052976561438443\n",
            "Train loss: 2.280111312866211\n",
            "\n",
            "Time (s): 0.511028528213501\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 371 / 480\n",
            "LR: 0.0004052806135831848\n",
            "Train loss: 2.140305757522583\n",
            "\n",
            "Time (s): 0.5124828815460205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 372 / 480\n",
            "LR: 0.00040526357317223764\n",
            "Train loss: 2.2275025844573975\n",
            "\n",
            "Time (s): 0.5120909214019775\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 373 / 480\n",
            "LR: 0.0004052465349105508\n",
            "Train loss: 2.1267127990722656\n",
            "\n",
            "Time (s): 0.5113894939422607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 374 / 480\n",
            "LR: 0.00040522949879767266\n",
            "Train loss: 2.3484983444213867\n",
            "\n",
            "Time (s): 0.5048227310180664\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 375 / 480\n",
            "LR: 0.00040521246483315147\n",
            "Train loss: 1.9847464561462402\n",
            "\n",
            "Time (s): 0.505645751953125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 376 / 480\n",
            "LR: 0.00040519543301653584\n",
            "Train loss: 2.3082504272460938\n",
            "\n",
            "Time (s): 0.5139608383178711\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 377 / 480\n",
            "LR: 0.0004051784033473743\n",
            "Train loss: 2.1889963150024414\n",
            "\n",
            "Time (s): 0.5104334354400635\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 378 / 480\n",
            "LR: 0.0004051613758252156\n",
            "Train loss: 2.1582272052764893\n",
            "\n",
            "Time (s): 0.507498025894165\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 379 / 480\n",
            "LR: 0.0004051443504496087\n",
            "Train loss: 2.4049246311187744\n",
            "\n",
            "Time (s): 0.5085422992706299\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 380 / 480\n",
            "LR: 0.0004051273272201027\n",
            "Train loss: 2.2305400371551514\n",
            "\n",
            "Time (s): 0.5108211040496826\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 381 / 480\n",
            "LR: 0.00040511030613624675\n",
            "Train loss: 1.9627742767333984\n",
            "\n",
            "Time (s): 0.5112667083740234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 382 / 480\n",
            "LR: 0.00040509328719759\n",
            "Train loss: 2.177414655685425\n",
            "\n",
            "Time (s): 0.5138993263244629\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 383 / 480\n",
            "LR: 0.000405076270403682\n",
            "Train loss: 2.286407470703125\n",
            "\n",
            "Time (s): 0.5177712440490723\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 384 / 480\n",
            "LR: 0.00040505925575407237\n",
            "Train loss: 2.2151410579681396\n",
            "\n",
            "Time (s): 0.5253288745880127\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 385 / 480\n",
            "LR: 0.0004050422432483107\n",
            "Train loss: 2.3962204456329346\n",
            "\n",
            "Time (s): 0.5277822017669678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 386 / 480\n",
            "LR: 0.00040502523288594685\n",
            "Train loss: 2.1004981994628906\n",
            "\n",
            "Time (s): 0.5218873023986816\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 387 / 480\n",
            "LR: 0.0004050082246665307\n",
            "Train loss: 2.1671366691589355\n",
            "\n",
            "Time (s): 0.5285627841949463\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 388 / 480\n",
            "LR: 0.00040499121858961256\n",
            "Train loss: 2.2372419834136963\n",
            "\n",
            "Time (s): 0.5236110687255859\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 389 / 480\n",
            "LR: 0.0004049742146547425\n",
            "Train loss: 2.1079399585723877\n",
            "\n",
            "Time (s): 0.5232267379760742\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 390 / 480\n",
            "LR: 0.00040495721286147086\n",
            "Train loss: 2.0100436210632324\n",
            "\n",
            "Time (s): 0.5112485885620117\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 391 / 480\n",
            "LR: 0.0004049402132093482\n",
            "Train loss: 2.4944684505462646\n",
            "\n",
            "Time (s): 0.5146751403808594\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 392 / 480\n",
            "LR: 0.0004049232156979251\n",
            "Train loss: 2.3182315826416016\n",
            "\n",
            "Time (s): 0.506375789642334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 393 / 480\n",
            "LR: 0.00040490622032675236\n",
            "Train loss: 2.2719292640686035\n",
            "\n",
            "Time (s): 0.5071001052856445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 394 / 480\n",
            "LR: 0.0004048892270953808\n",
            "Train loss: 2.605118989944458\n",
            "\n",
            "Time (s): 0.5072958469390869\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 395 / 480\n",
            "LR: 0.00040487223600336157\n",
            "Train loss: 2.3811111450195312\n",
            "\n",
            "Time (s): 0.5132966041564941\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 396 / 480\n",
            "LR: 0.00040485524705024563\n",
            "Train loss: 2.161292314529419\n",
            "\n",
            "Time (s): 0.5176174640655518\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 397 / 480\n",
            "LR: 0.0004048382602355844\n",
            "Train loss: 2.1462619304656982\n",
            "\n",
            "Time (s): 0.5115795135498047\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 398 / 480\n",
            "LR: 0.0004048212755589293\n",
            "Train loss: 2.228778600692749\n",
            "\n",
            "Time (s): 0.5110664367675781\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 399 / 480\n",
            "LR: 0.0004048042930198318\n",
            "Train loss: 2.102738380432129\n",
            "\n",
            "Time (s): 0.508352518081665\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 400 / 480\n",
            "LR: 0.0004047873126178435\n",
            "Train loss: 2.199965715408325\n",
            "\n",
            "Time (s): 0.5116245746612549\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 401 / 480\n",
            "LR: 0.0004047703343525165\n",
            "Train loss: 2.141425132751465\n",
            "\n",
            "Time (s): 0.5098116397857666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 402 / 480\n",
            "LR: 0.00040475335822340243\n",
            "Train loss: 2.325922966003418\n",
            "\n",
            "Time (s): 0.5107874870300293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 403 / 480\n",
            "LR: 0.00040473638423005353\n",
            "Train loss: 2.0898871421813965\n",
            "\n",
            "Time (s): 0.5118672847747803\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 404 / 480\n",
            "LR: 0.00040471941237202195\n",
            "Train loss: 2.1639301776885986\n",
            "\n",
            "Time (s): 0.5084872245788574\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 405 / 480\n",
            "LR: 0.00040470244264886006\n",
            "Train loss: 2.306025743484497\n",
            "\n",
            "Time (s): 0.5107376575469971\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 406 / 480\n",
            "LR: 0.00040468547506012026\n",
            "Train loss: 1.9813472032546997\n",
            "\n",
            "Time (s): 0.5116093158721924\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 407 / 480\n",
            "LR: 0.0004046685096053552\n",
            "Train loss: 1.9525794982910156\n",
            "\n",
            "Time (s): 0.5078463554382324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 408 / 480\n",
            "LR: 0.00040465154628411767\n",
            "Train loss: 2.3598852157592773\n",
            "\n",
            "Time (s): 0.5052475929260254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 409 / 480\n",
            "LR: 0.00040463458509596036\n",
            "Train loss: 2.1598732471466064\n",
            "\n",
            "Time (s): 0.5215437412261963\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 410 / 480\n",
            "LR: 0.0004046176260404364\n",
            "Train loss: 2.29304575920105\n",
            "\n",
            "Time (s): 0.515350341796875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 411 / 480\n",
            "LR: 0.0004046006691170989\n",
            "Train loss: 2.1008119583129883\n",
            "\n",
            "Time (s): 0.52166748046875\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 412 / 480\n",
            "LR: 0.0004045837143255011\n",
            "Train loss: 2.093996286392212\n",
            "\n",
            "Time (s): 0.5176916122436523\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 413 / 480\n",
            "LR: 0.00040456676166519633\n",
            "Train loss: 2.258920907974243\n",
            "\n",
            "Time (s): 0.5232822895050049\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 414 / 480\n",
            "LR: 0.00040454981113573815\n",
            "Train loss: 1.945091962814331\n",
            "\n",
            "Time (s): 0.5138533115386963\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 415 / 480\n",
            "LR: 0.00040453286273668025\n",
            "Train loss: 2.1613645553588867\n",
            "\n",
            "Time (s): 0.5131628513336182\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 416 / 480\n",
            "LR: 0.0004045159164675763\n",
            "Train loss: 2.0354743003845215\n",
            "\n",
            "Time (s): 0.5105714797973633\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 417 / 480\n",
            "LR: 0.0004044989723279803\n",
            "Train loss: 1.9487628936767578\n",
            "\n",
            "Time (s): 0.5130836963653564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 418 / 480\n",
            "LR: 0.00040448203031744626\n",
            "Train loss: 2.230424165725708\n",
            "\n",
            "Time (s): 0.5060858726501465\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 419 / 480\n",
            "LR: 0.0004044650904355283\n",
            "Train loss: 2.226386547088623\n",
            "\n",
            "Time (s): 0.5081346035003662\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 420 / 480\n",
            "LR: 0.0004044481526817809\n",
            "Train loss: 1.9870023727416992\n",
            "\n",
            "Time (s): 0.5084543228149414\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 421 / 480\n",
            "LR: 0.0004044312170557583\n",
            "Train loss: 2.193020820617676\n",
            "\n",
            "Time (s): 0.5079331398010254\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 422 / 480\n",
            "LR: 0.00040441428355701513\n",
            "Train loss: 2.258408784866333\n",
            "\n",
            "Time (s): 0.5058581829071045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 423 / 480\n",
            "LR: 0.000404397352185106\n",
            "Train loss: 1.843344807624817\n",
            "\n",
            "Time (s): 0.5103981494903564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 424 / 480\n",
            "LR: 0.00040438042293958594\n",
            "Train loss: 2.0649073123931885\n",
            "\n",
            "Time (s): 0.5120177268981934\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 425 / 480\n",
            "LR: 0.00040436349582000965\n",
            "Train loss: 2.022019147872925\n",
            "\n",
            "Time (s): 0.5155432224273682\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 426 / 480\n",
            "LR: 0.00040434657082593235\n",
            "Train loss: 1.9707773923873901\n",
            "\n",
            "Time (s): 0.509958028793335\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 427 / 480\n",
            "LR: 0.00040432964795690936\n",
            "Train loss: 2.2423055171966553\n",
            "\n",
            "Time (s): 0.5057306289672852\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 428 / 480\n",
            "LR: 0.0004043127272124957\n",
            "Train loss: 2.044921875\n",
            "\n",
            "Time (s): 0.5056419372558594\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 429 / 480\n",
            "LR: 0.0004042958085922472\n",
            "Train loss: 2.364932060241699\n",
            "\n",
            "Time (s): 0.5070383548736572\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 430 / 480\n",
            "LR: 0.0004042788920957193\n",
            "Train loss: 2.068941116333008\n",
            "\n",
            "Time (s): 0.5055866241455078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 431 / 480\n",
            "LR: 0.0004042619777224677\n",
            "Train loss: 2.0517945289611816\n",
            "\n",
            "Time (s): 0.5046851634979248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 432 / 480\n",
            "LR: 0.0004042450654720483\n",
            "Train loss: 2.0759243965148926\n",
            "\n",
            "Time (s): 0.5122811794281006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 433 / 480\n",
            "LR: 0.00040422815534401713\n",
            "Train loss: 2.1044375896453857\n",
            "\n",
            "Time (s): 0.507565975189209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 434 / 480\n",
            "LR: 0.0004042112473379303\n",
            "Train loss: 2.4556515216827393\n",
            "\n",
            "Time (s): 0.512352466583252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 435 / 480\n",
            "LR: 0.0004041943414533441\n",
            "Train loss: 2.173672914505005\n",
            "\n",
            "Time (s): 0.5150268077850342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 436 / 480\n",
            "LR: 0.0004041774376898148\n",
            "Train loss: 2.4304935932159424\n",
            "\n",
            "Time (s): 0.5309410095214844\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 437 / 480\n",
            "LR: 0.00040416053604689907\n",
            "Train loss: 2.5469799041748047\n",
            "\n",
            "Time (s): 0.5187270641326904\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 438 / 480\n",
            "LR: 0.00040414363652415336\n",
            "Train loss: 2.05141544342041\n",
            "\n",
            "Time (s): 0.5293493270874023\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 439 / 480\n",
            "LR: 0.00040412673912113467\n",
            "Train loss: 2.062166213989258\n",
            "\n",
            "Time (s): 0.5166878700256348\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 440 / 480\n",
            "LR: 0.00040410984383739974\n",
            "Train loss: 1.9800217151641846\n",
            "\n",
            "Time (s): 0.509566068649292\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 441 / 480\n",
            "LR: 0.0004040929506725056\n",
            "Train loss: 2.1494758129119873\n",
            "\n",
            "Time (s): 0.5267829895019531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 442 / 480\n",
            "LR: 0.00040407605962600955\n",
            "Train loss: 2.2718498706817627\n",
            "\n",
            "Time (s): 0.5331788063049316\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 443 / 480\n",
            "LR: 0.00040405917069746876\n",
            "Train loss: 2.150423049926758\n",
            "\n",
            "Time (s): 0.5105917453765869\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 444 / 480\n",
            "LR: 0.0004040422838864407\n",
            "Train loss: 2.232281446456909\n",
            "\n",
            "Time (s): 0.5067059993743896\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 445 / 480\n",
            "LR: 0.0004040253991924829\n",
            "Train loss: 2.202019691467285\n",
            "\n",
            "Time (s): 0.5110561847686768\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 446 / 480\n",
            "LR: 0.0004040085166151531\n",
            "Train loss: 2.27517032623291\n",
            "\n",
            "Time (s): 0.5069446563720703\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 447 / 480\n",
            "LR: 0.000403991636154009\n",
            "Train loss: 2.0680031776428223\n",
            "\n",
            "Time (s): 0.5130939483642578\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 448 / 480\n",
            "LR: 0.0004039747578086087\n",
            "Train loss: 2.0419559478759766\n",
            "\n",
            "Time (s): 0.5076823234558105\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 449 / 480\n",
            "LR: 0.00040395788157851015\n",
            "Train loss: 2.1332292556762695\n",
            "\n",
            "Time (s): 0.5074419975280762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 450 / 480\n",
            "LR: 0.00040394100746327154\n",
            "Train loss: 2.062772512435913\n",
            "\n",
            "Time (s): 0.5089371204376221\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 451 / 480\n",
            "LR: 0.00040392413546245116\n",
            "Train loss: 2.4506447315216064\n",
            "\n",
            "Time (s): 0.5107228755950928\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 452 / 480\n",
            "LR: 0.00040390726557560763\n",
            "Train loss: 2.207432746887207\n",
            "\n",
            "Time (s): 0.5103800296783447\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 453 / 480\n",
            "LR: 0.0004038903978022994\n",
            "Train loss: 2.0855040550231934\n",
            "\n",
            "Time (s): 0.5060575008392334\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 454 / 480\n",
            "LR: 0.0004038735321420853\n",
            "Train loss: 2.0483286380767822\n",
            "\n",
            "Time (s): 0.5062837600708008\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 455 / 480\n",
            "LR: 0.00040385666859452405\n",
            "Train loss: 2.223241090774536\n",
            "\n",
            "Time (s): 0.5089645385742188\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 456 / 480\n",
            "LR: 0.00040383980715917464\n",
            "Train loss: 2.0356204509735107\n",
            "\n",
            "Time (s): 0.5067875385284424\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 457 / 480\n",
            "LR: 0.0004038229478355962\n",
            "Train loss: 2.176316499710083\n",
            "\n",
            "Time (s): 0.5095667839050293\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 458 / 480\n",
            "LR: 0.00040380609062334806\n",
            "Train loss: 2.415294885635376\n",
            "\n",
            "Time (s): 0.5111839771270752\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 459 / 480\n",
            "LR: 0.00040378923552198944\n",
            "Train loss: 2.018903970718384\n",
            "\n",
            "Time (s): 0.508192777633667\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 460 / 480\n",
            "LR: 0.0004037723825310799\n",
            "Train loss: 2.0024197101593018\n",
            "\n",
            "Time (s): 0.5114631652832031\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 461 / 480\n",
            "LR: 0.00040375553165017896\n",
            "Train loss: 2.1950621604919434\n",
            "\n",
            "Time (s): 0.5148575305938721\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 462 / 480\n",
            "LR: 0.00040373868287884646\n",
            "Train loss: 2.5231776237487793\n",
            "\n",
            "Time (s): 0.5134909152984619\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 463 / 480\n",
            "LR: 0.00040372183621664227\n",
            "Train loss: 2.301835536956787\n",
            "\n",
            "Time (s): 0.5187125205993652\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 464 / 480\n",
            "LR: 0.00040370499166312635\n",
            "Train loss: 2.271421194076538\n",
            "\n",
            "Time (s): 0.5226936340332031\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 465 / 480\n",
            "LR: 0.00040368814921785886\n",
            "Train loss: 2.105628252029419\n",
            "\n",
            "Time (s): 0.5149176120758057\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 466 / 480\n",
            "LR: 0.00040367130888040013\n",
            "Train loss: 2.037336826324463\n",
            "\n",
            "Time (s): 0.5190913677215576\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 467 / 480\n",
            "LR: 0.00040365447065031037\n",
            "Train loss: 2.0025434494018555\n",
            "\n",
            "Time (s): 0.5276830196380615\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 468 / 480\n",
            "LR: 0.0004036376345271502\n",
            "Train loss: 2.2879340648651123\n",
            "\n",
            "Time (s): 0.5208721160888672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 469 / 480\n",
            "LR: 0.0004036208005104804\n",
            "Train loss: 2.355051279067993\n",
            "\n",
            "Time (s): 0.5198662281036377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 470 / 480\n",
            "LR: 0.0004036039685998614\n",
            "Train loss: 2.138000726699829\n",
            "\n",
            "Time (s): 0.5061016082763672\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 471 / 480\n",
            "LR: 0.0004035871387948544\n",
            "Train loss: 2.4194693565368652\n",
            "\n",
            "Time (s): 0.5091540813446045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 472 / 480\n",
            "LR: 0.0004035703110950204\n",
            "Train loss: 2.4496243000030518\n",
            "\n",
            "Time (s): 0.5063402652740479\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 473 / 480\n",
            "LR: 0.00040355348549992034\n",
            "Train loss: 2.1307432651519775\n",
            "\n",
            "Time (s): 0.5053322315216064\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 474 / 480\n",
            "LR: 0.0004035366620091158\n",
            "Train loss: 2.2267813682556152\n",
            "\n",
            "Time (s): 0.5112688541412354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 475 / 480\n",
            "LR: 0.00040351984062216793\n",
            "Train loss: 2.0968079566955566\n",
            "\n",
            "Time (s): 0.5119571685791016\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 476 / 480\n",
            "LR: 0.00040350302133863853\n",
            "Train loss: 2.034067153930664\n",
            "\n",
            "Time (s): 0.5126395225524902\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 477 / 480\n",
            "LR: 0.0004034862041580891\n",
            "Train loss: 2.4369516372680664\n",
            "\n",
            "Time (s): 0.5115995407104492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 478 / 480\n",
            "LR: 0.0004034693890800813\n",
            "Train loss: 2.1706957817077637\n",
            "\n",
            "Time (s): 0.5158417224884033\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 479 / 480\n",
            "LR: 0.00040345257610417744\n",
            "Train loss: 2.1358022689819336\n",
            "\n",
            "Time (s): 0.5118062496185303\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 25  Batch 480 / 480\n",
            "LR: 0.0004034357652299392\n",
            "Train loss: 2.142354965209961\n",
            "\n",
            "Time (s): 0.5085184574127197\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Evaluating:\n",
            "Epoch: 25\n",
            "Avg train loss: 2.071176205078761\n",
            "Avg train acc: 0.3961732255915801\n",
            "Avg eval loss: 2.1676016504114326\n",
            "Avg eval acc: 0.37891734730113635\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "NEW EPOCH: 26\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 1 / 480\n",
            "LR: 0.00040341895645692896\n",
            "Train loss: 2.1805481910705566\n",
            "\n",
            "Time (s): 0.5547468662261963\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 2 / 480\n",
            "LR: 0.000403402149784709\n",
            "Train loss: 1.998496174812317\n",
            "\n",
            "Time (s): 0.5240795612335205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 3 / 480\n",
            "LR: 0.0004033853452128417\n",
            "Train loss: 2.155177116394043\n",
            "\n",
            "Time (s): 0.5227658748626709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 4 / 480\n",
            "LR: 0.0004033685427408898\n",
            "Train loss: 2.4056777954101562\n",
            "\n",
            "Time (s): 0.5193686485290527\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 5 / 480\n",
            "LR: 0.0004033517423684157\n",
            "Train loss: 2.1656558513641357\n",
            "\n",
            "Time (s): 0.515470027923584\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 6 / 480\n",
            "LR: 0.0004033349440949824\n",
            "Train loss: 2.102694034576416\n",
            "\n",
            "Time (s): 0.5100057125091553\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 7 / 480\n",
            "LR: 0.00040331814792015286\n",
            "Train loss: 2.2403557300567627\n",
            "\n",
            "Time (s): 0.5105395317077637\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 8 / 480\n",
            "LR: 0.00040330135384349005\n",
            "Train loss: 2.2666819095611572\n",
            "\n",
            "Time (s): 0.5057578086853027\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 9 / 480\n",
            "LR: 0.0004032845618645573\n",
            "Train loss: 2.3652846813201904\n",
            "\n",
            "Time (s): 0.5061757564544678\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 10 / 480\n",
            "LR: 0.0004032677719829178\n",
            "Train loss: 2.2851498126983643\n",
            "\n",
            "Time (s): 0.5073220729827881\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 11 / 480\n",
            "LR: 0.00040325098419813506\n",
            "Train loss: 2.3789775371551514\n",
            "\n",
            "Time (s): 0.5107803344726562\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 12 / 480\n",
            "LR: 0.0004032341985097728\n",
            "Train loss: 2.3197925090789795\n",
            "\n",
            "Time (s): 0.5051259994506836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 13 / 480\n",
            "LR: 0.0004032174149173945\n",
            "Train loss: 2.2529146671295166\n",
            "\n",
            "Time (s): 0.506495475769043\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 14 / 480\n",
            "LR: 0.0004032006334205641\n",
            "Train loss: 2.2569422721862793\n",
            "\n",
            "Time (s): 0.503546953201294\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 15 / 480\n",
            "LR: 0.00040318385401884554\n",
            "Train loss: 2.1365292072296143\n",
            "\n",
            "Time (s): 0.5085954666137695\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 16 / 480\n",
            "LR: 0.00040316707671180304\n",
            "Train loss: 2.158945322036743\n",
            "\n",
            "Time (s): 0.5107178688049316\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 17 / 480\n",
            "LR: 0.0004031503014990006\n",
            "Train loss: 2.272336006164551\n",
            "\n",
            "Time (s): 0.5184121131896973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 18 / 480\n",
            "LR: 0.00040313352838000275\n",
            "Train loss: 2.0969555377960205\n",
            "\n",
            "Time (s): 0.5284919738769531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 19 / 480\n",
            "LR: 0.00040311675735437384\n",
            "Train loss: 2.1771090030670166\n",
            "\n",
            "Time (s): 0.5346415042877197\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 20 / 480\n",
            "LR: 0.0004030999884216785\n",
            "Train loss: 2.023608922958374\n",
            "\n",
            "Time (s): 0.531829833984375\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 21 / 480\n",
            "LR: 0.00040308322158148156\n",
            "Train loss: 2.1172330379486084\n",
            "\n",
            "Time (s): 0.5254731178283691\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 22 / 480\n",
            "LR: 0.00040306645683334773\n",
            "Train loss: 2.299367666244507\n",
            "\n",
            "Time (s): 0.524695634841919\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 23 / 480\n",
            "LR: 0.00040304969417684204\n",
            "Train loss: 1.9449766874313354\n",
            "\n",
            "Time (s): 0.5253095626831055\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 24 / 480\n",
            "LR: 0.0004030329336115296\n",
            "Train loss: 2.181192636489868\n",
            "\n",
            "Time (s): 0.5149133205413818\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 25 / 480\n",
            "LR: 0.00040301617513697563\n",
            "Train loss: 2.341129779815674\n",
            "\n",
            "Time (s): 0.5159785747528076\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 26 / 480\n",
            "LR: 0.00040299941875274545\n",
            "Train loss: 2.324726104736328\n",
            "\n",
            "Time (s): 0.5170779228210449\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 27 / 480\n",
            "LR: 0.0004029826644584046\n",
            "Train loss: 2.1065285205841064\n",
            "\n",
            "Time (s): 0.51218581199646\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 28 / 480\n",
            "LR: 0.00040296591225351874\n",
            "Train loss: 2.3869590759277344\n",
            "\n",
            "Time (s): 0.5071277618408203\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 29 / 480\n",
            "LR: 0.0004029491621376535\n",
            "Train loss: 2.1341068744659424\n",
            "\n",
            "Time (s): 0.5149145126342773\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 30 / 480\n",
            "LR: 0.00040293241411037484\n",
            "Train loss: 2.2055747509002686\n",
            "\n",
            "Time (s): 0.5102543830871582\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 31 / 480\n",
            "LR: 0.00040291566817124864\n",
            "Train loss: 1.9352821111679077\n",
            "\n",
            "Time (s): 0.5096113681793213\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 32 / 480\n",
            "LR: 0.00040289892431984116\n",
            "Train loss: 2.202085018157959\n",
            "\n",
            "Time (s): 0.5122344493865967\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 33 / 480\n",
            "LR: 0.00040288218255571845\n",
            "Train loss: 2.2057602405548096\n",
            "\n",
            "Time (s): 0.5057883262634277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 34 / 480\n",
            "LR: 0.00040286544287844705\n",
            "Train loss: 2.180175542831421\n",
            "\n",
            "Time (s): 0.5073707103729248\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 35 / 480\n",
            "LR: 0.0004028487052875934\n",
            "Train loss: 1.9867823123931885\n",
            "\n",
            "Time (s): 0.5107643604278564\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 36 / 480\n",
            "LR: 0.0004028319697827241\n",
            "Train loss: 1.90291428565979\n",
            "\n",
            "Time (s): 0.5115485191345215\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 37 / 480\n",
            "LR: 0.0004028152363634059\n",
            "Train loss: 2.157027006149292\n",
            "\n",
            "Time (s): 0.5110883712768555\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 38 / 480\n",
            "LR: 0.0004027985050292057\n",
            "Train loss: 2.014228343963623\n",
            "\n",
            "Time (s): 0.5077800750732422\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 39 / 480\n",
            "LR: 0.0004027817757796905\n",
            "Train loss: 2.2549407482147217\n",
            "\n",
            "Time (s): 0.5046043395996094\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 40 / 480\n",
            "LR: 0.0004027650486144274\n",
            "Train loss: 1.969904899597168\n",
            "\n",
            "Time (s): 0.51373291015625\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 41 / 480\n",
            "LR: 0.0004027483235329836\n",
            "Train loss: 2.2415249347686768\n",
            "\n",
            "Time (s): 0.5125033855438232\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 42 / 480\n",
            "LR: 0.00040273160053492656\n",
            "Train loss: 2.3080101013183594\n",
            "\n",
            "Time (s): 0.5116186141967773\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 43 / 480\n",
            "LR: 0.00040271487961982374\n",
            "Train loss: 2.153930902481079\n",
            "\n",
            "Time (s): 0.5202744007110596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 44 / 480\n",
            "LR: 0.0004026981607872428\n",
            "Train loss: 2.300382614135742\n",
            "\n",
            "Time (s): 0.5414896011352539\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 45 / 480\n",
            "LR: 0.0004026814440367515\n",
            "Train loss: 2.286550998687744\n",
            "\n",
            "Time (s): 0.5317134857177734\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 46 / 480\n",
            "LR: 0.00040266472936791763\n",
            "Train loss: 2.171570062637329\n",
            "\n",
            "Time (s): 0.5222795009613037\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 47 / 480\n",
            "LR: 0.00040264801678030937\n",
            "Train loss: 2.1344363689422607\n",
            "\n",
            "Time (s): 0.5227792263031006\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 48 / 480\n",
            "LR: 0.0004026313062734946\n",
            "Train loss: 1.9519022703170776\n",
            "\n",
            "Time (s): 0.528693437576294\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 49 / 480\n",
            "LR: 0.0004026145978470418\n",
            "Train loss: 2.2674427032470703\n",
            "\n",
            "Time (s): 0.5282001495361328\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 50 / 480\n",
            "LR: 0.0004025978915005193\n",
            "Train loss: 2.3067855834960938\n",
            "\n",
            "Time (s): 0.5264980792999268\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 51 / 480\n",
            "LR: 0.00040258118723349547\n",
            "Train loss: 2.1947968006134033\n",
            "\n",
            "Time (s): 0.5119330883026123\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 52 / 480\n",
            "LR: 0.00040256448504553906\n",
            "Train loss: 2.25689959526062\n",
            "\n",
            "Time (s): 0.51277756690979\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 53 / 480\n",
            "LR: 0.00040254778493621884\n",
            "Train loss: 2.2196290493011475\n",
            "\n",
            "Time (s): 0.5097219944000244\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 54 / 480\n",
            "LR: 0.0004025310869051037\n",
            "Train loss: 2.125331163406372\n",
            "\n",
            "Time (s): 0.5092973709106445\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 55 / 480\n",
            "LR: 0.00040251439095176253\n",
            "Train loss: 2.3150475025177\n",
            "\n",
            "Time (s): 0.5098171234130859\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 56 / 480\n",
            "LR: 0.0004024976970757646\n",
            "Train loss: 1.927725076675415\n",
            "\n",
            "Time (s): 0.5160503387451172\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 57 / 480\n",
            "LR: 0.00040248100527667905\n",
            "Train loss: 1.9372589588165283\n",
            "\n",
            "Time (s): 0.519768238067627\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 58 / 480\n",
            "LR: 0.00040246431555407533\n",
            "Train loss: 2.272223949432373\n",
            "\n",
            "Time (s): 0.5205674171447754\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 59 / 480\n",
            "LR: 0.0004024476279075229\n",
            "Train loss: 2.398184299468994\n",
            "\n",
            "Time (s): 0.5180771350860596\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 60 / 480\n",
            "LR: 0.0004024309423365915\n",
            "Train loss: 2.4026029109954834\n",
            "\n",
            "Time (s): 0.5109992027282715\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 61 / 480\n",
            "LR: 0.0004024142588408508\n",
            "Train loss: 2.1435160636901855\n",
            "\n",
            "Time (s): 0.5062575340270996\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 62 / 480\n",
            "LR: 0.0004023975774198707\n",
            "Train loss: 2.4555420875549316\n",
            "\n",
            "Time (s): 0.505711555480957\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 63 / 480\n",
            "LR: 0.0004023808980732212\n",
            "Train loss: 2.123701333999634\n",
            "\n",
            "Time (s): 0.5159151554107666\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 64 / 480\n",
            "LR: 0.0004023642208004724\n",
            "Train loss: 1.9453258514404297\n",
            "\n",
            "Time (s): 0.5076291561126709\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 65 / 480\n",
            "LR: 0.00040234754560119465\n",
            "Train loss: 2.1686136722564697\n",
            "\n",
            "Time (s): 0.5079965591430664\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 66 / 480\n",
            "LR: 0.0004023308724749582\n",
            "Train loss: 2.0785117149353027\n",
            "\n",
            "Time (s): 0.5056707859039307\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 67 / 480\n",
            "LR: 0.0004023142014213337\n",
            "Train loss: 2.178677797317505\n",
            "\n",
            "Time (s): 0.507246732711792\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 68 / 480\n",
            "LR: 0.0004022975324398917\n",
            "Train loss: 2.2245020866394043\n",
            "\n",
            "Time (s): 0.5097188949584961\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 69 / 480\n",
            "LR: 0.0004022808655302029\n",
            "Train loss: 2.240772247314453\n",
            "\n",
            "Time (s): 0.5086636543273926\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 70 / 480\n",
            "LR: 0.00040226420069183825\n",
            "Train loss: 2.13157320022583\n",
            "\n",
            "Time (s): 0.523540735244751\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 71 / 480\n",
            "LR: 0.00040224753792436884\n",
            "Train loss: 2.3447389602661133\n",
            "\n",
            "Time (s): 0.5302681922912598\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 72 / 480\n",
            "LR: 0.0004022308772273656\n",
            "Train loss: 2.1663248538970947\n",
            "\n",
            "Time (s): 0.5326719284057617\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 73 / 480\n",
            "LR: 0.0004022142186003999\n",
            "Train loss: 2.1700403690338135\n",
            "\n",
            "Time (s): 0.5184447765350342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 74 / 480\n",
            "LR: 0.0004021975620430431\n",
            "Train loss: 1.9488662481307983\n",
            "\n",
            "Time (s): 0.5197436809539795\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 75 / 480\n",
            "LR: 0.0004021809075548668\n",
            "Train loss: 2.090919017791748\n",
            "\n",
            "Time (s): 0.5196950435638428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 76 / 480\n",
            "LR: 0.0004021642551354424\n",
            "Train loss: 1.958268404006958\n",
            "\n",
            "Time (s): 0.5191614627838135\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 77 / 480\n",
            "LR: 0.0004021476047843419\n",
            "Train loss: 2.509514808654785\n",
            "\n",
            "Time (s): 0.51104736328125\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 78 / 480\n",
            "LR: 0.0004021309565011369\n",
            "Train loss: 2.2758126258850098\n",
            "\n",
            "Time (s): 0.5108981132507324\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 79 / 480\n",
            "LR: 0.0004021143102853996\n",
            "Train loss: 2.121213436126709\n",
            "\n",
            "Time (s): 0.5085372924804688\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 80 / 480\n",
            "LR: 0.0004020976661367021\n",
            "Train loss: 1.985486388206482\n",
            "\n",
            "Time (s): 0.5094802379608154\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 81 / 480\n",
            "LR: 0.0004020810240546166\n",
            "Train loss: 2.1036503314971924\n",
            "\n",
            "Time (s): 0.5113704204559326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 82 / 480\n",
            "LR: 0.0004020643840387155\n",
            "Train loss: 2.1548407077789307\n",
            "\n",
            "Time (s): 0.5124804973602295\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 83 / 480\n",
            "LR: 0.00040204774608857124\n",
            "Train loss: 2.505725622177124\n",
            "\n",
            "Time (s): 0.5088179111480713\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 84 / 480\n",
            "LR: 0.00040203111020375645\n",
            "Train loss: 2.4229211807250977\n",
            "\n",
            "Time (s): 0.5103070735931396\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 85 / 480\n",
            "LR: 0.00040201447638384396\n",
            "Train loss: 1.9701032638549805\n",
            "\n",
            "Time (s): 0.5087878704071045\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 86 / 480\n",
            "LR: 0.00040199784462840657\n",
            "Train loss: 2.0144898891448975\n",
            "\n",
            "Time (s): 0.5101799964904785\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 87 / 480\n",
            "LR: 0.0004019812149370171\n",
            "Train loss: 2.008758068084717\n",
            "\n",
            "Time (s): 0.5088310241699219\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 88 / 480\n",
            "LR: 0.000401964587309249\n",
            "Train loss: 2.2657155990600586\n",
            "\n",
            "Time (s): 0.5147414207458496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 89 / 480\n",
            "LR: 0.00040194796174467526\n",
            "Train loss: 2.1532270908355713\n",
            "\n",
            "Time (s): 0.5053756237030029\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 90 / 480\n",
            "LR: 0.0004019313382428694\n",
            "Train loss: 2.388235092163086\n",
            "\n",
            "Time (s): 0.5050294399261475\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 91 / 480\n",
            "LR: 0.00040191471680340473\n",
            "Train loss: 2.3193681240081787\n",
            "\n",
            "Time (s): 0.506633996963501\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 92 / 480\n",
            "LR: 0.0004018980974258549\n",
            "Train loss: 2.2310781478881836\n",
            "\n",
            "Time (s): 0.509782075881958\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 93 / 480\n",
            "LR: 0.00040188148010979376\n",
            "Train loss: 2.178375720977783\n",
            "\n",
            "Time (s): 0.5091671943664551\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 94 / 480\n",
            "LR: 0.000401864864854795\n",
            "Train loss: 2.5333163738250732\n",
            "\n",
            "Time (s): 0.5071122646331787\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 95 / 480\n",
            "LR: 0.00040184825166043273\n",
            "Train loss: 2.0262656211853027\n",
            "\n",
            "Time (s): 0.5109004974365234\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 96 / 480\n",
            "LR: 0.00040183164052628095\n",
            "Train loss: 2.567854881286621\n",
            "\n",
            "Time (s): 0.5087196826934814\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 97 / 480\n",
            "LR: 0.000401815031451914\n",
            "Train loss: 2.1282830238342285\n",
            "\n",
            "Time (s): 0.511864185333252\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 98 / 480\n",
            "LR: 0.00040179842443690606\n",
            "Train loss: 1.9170832633972168\n",
            "\n",
            "Time (s): 0.5140156745910645\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 99 / 480\n",
            "LR: 0.00040178181948083175\n",
            "Train loss: 1.8808062076568604\n",
            "\n",
            "Time (s): 0.5145680904388428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 100 / 480\n",
            "LR: 0.0004017652165832656\n",
            "Train loss: 2.0414395332336426\n",
            "\n",
            "Time (s): 0.5144267082214355\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 101 / 480\n",
            "LR: 0.00040174861574378235\n",
            "Train loss: 2.4332828521728516\n",
            "\n",
            "Time (s): 0.5214939117431641\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 102 / 480\n",
            "LR: 0.0004017320169619567\n",
            "Train loss: 2.185232400894165\n",
            "\n",
            "Time (s): 0.5135359764099121\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 103 / 480\n",
            "LR: 0.00040171542023736387\n",
            "Train loss: 1.9867522716522217\n",
            "\n",
            "Time (s): 0.5146198272705078\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 104 / 480\n",
            "LR: 0.0004016988255695787\n",
            "Train loss: 1.9305832386016846\n",
            "\n",
            "Time (s): 0.5161123275756836\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 105 / 480\n",
            "LR: 0.00040168223295817656\n",
            "Train loss: 1.8125969171524048\n",
            "\n",
            "Time (s): 0.50777268409729\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 106 / 480\n",
            "LR: 0.0004016656424027327\n",
            "Train loss: 2.0625863075256348\n",
            "\n",
            "Time (s): 0.5068116188049316\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 107 / 480\n",
            "LR: 0.0004016490539028225\n",
            "Train loss: 2.1009089946746826\n",
            "\n",
            "Time (s): 0.5047297477722168\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 108 / 480\n",
            "LR: 0.00040163246745802175\n",
            "Train loss: 2.1531007289886475\n",
            "\n",
            "Time (s): 0.5106430053710938\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 109 / 480\n",
            "LR: 0.00040161588306790593\n",
            "Train loss: 2.2557382583618164\n",
            "\n",
            "Time (s): 0.5082712173461914\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 110 / 480\n",
            "LR: 0.000401599300732051\n",
            "Train loss: 2.253474473953247\n",
            "\n",
            "Time (s): 0.5082492828369141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 111 / 480\n",
            "LR: 0.00040158272045003274\n",
            "Train loss: 2.0751476287841797\n",
            "\n",
            "Time (s): 0.5108106136322021\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 112 / 480\n",
            "LR: 0.00040156614222142746\n",
            "Train loss: 2.2520933151245117\n",
            "\n",
            "Time (s): 0.511390209197998\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 113 / 480\n",
            "LR: 0.00040154956604581115\n",
            "Train loss: 2.127613067626953\n",
            "\n",
            "Time (s): 0.5084152221679688\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 114 / 480\n",
            "LR: 0.00040153299192276026\n",
            "Train loss: 2.171076536178589\n",
            "\n",
            "Time (s): 0.5161950588226318\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 115 / 480\n",
            "LR: 0.0004015164198518511\n",
            "Train loss: 2.1445484161376953\n",
            "\n",
            "Time (s): 0.5118350982666016\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 116 / 480\n",
            "LR: 0.00040149984983266023\n",
            "Train loss: 2.330087184906006\n",
            "\n",
            "Time (s): 0.5099191665649414\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 117 / 480\n",
            "LR: 0.0004014832818647644\n",
            "Train loss: 2.354240655899048\n",
            "\n",
            "Time (s): 0.5086236000061035\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 118 / 480\n",
            "LR: 0.0004014667159477404\n",
            "Train loss: 2.2210347652435303\n",
            "\n",
            "Time (s): 0.5069923400878906\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 119 / 480\n",
            "LR: 0.00040145015208116507\n",
            "Train loss: 1.990169644355774\n",
            "\n",
            "Time (s): 0.5087630748748779\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 120 / 480\n",
            "LR: 0.00040143359026461554\n",
            "Train loss: 2.2407822608947754\n",
            "\n",
            "Time (s): 0.5111789703369141\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 121 / 480\n",
            "LR: 0.00040141703049766895\n",
            "Train loss: 2.1355302333831787\n",
            "\n",
            "Time (s): 0.5117297172546387\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 122 / 480\n",
            "LR: 0.0004014004727799027\n",
            "Train loss: 2.3411872386932373\n",
            "\n",
            "Time (s): 0.5139303207397461\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 123 / 480\n",
            "LR: 0.00040138391711089396\n",
            "Train loss: 2.1358747482299805\n",
            "\n",
            "Time (s): 0.5194921493530273\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 124 / 480\n",
            "LR: 0.0004013673634902204\n",
            "Train loss: 2.1085519790649414\n",
            "\n",
            "Time (s): 0.520380973815918\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 125 / 480\n",
            "LR: 0.00040135081191745967\n",
            "Train loss: 2.158808469772339\n",
            "\n",
            "Time (s): 0.5217363834381104\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 126 / 480\n",
            "LR: 0.00040133426239218956\n",
            "Train loss: 2.203174352645874\n",
            "\n",
            "Time (s): 0.5156128406524658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 127 / 480\n",
            "LR: 0.00040131771491398803\n",
            "Train loss: 1.9857040643692017\n",
            "\n",
            "Time (s): 0.5198249816894531\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 128 / 480\n",
            "LR: 0.0004013011694824329\n",
            "Train loss: 2.2645299434661865\n",
            "\n",
            "Time (s): 0.5118849277496338\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 129 / 480\n",
            "LR: 0.00040128462609710246\n",
            "Train loss: 2.0298268795013428\n",
            "\n",
            "Time (s): 0.5144133567810059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 130 / 480\n",
            "LR: 0.0004012680847575749\n",
            "Train loss: 2.241032123565674\n",
            "\n",
            "Time (s): 0.5196726322174072\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 131 / 480\n",
            "LR: 0.0004012515454634287\n",
            "Train loss: 2.222877025604248\n",
            "\n",
            "Time (s): 0.507117509841919\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 132 / 480\n",
            "LR: 0.00040123500821424233\n",
            "Train loss: 2.0323307514190674\n",
            "\n",
            "Time (s): 0.5053000450134277\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 133 / 480\n",
            "LR: 0.00040121847300959444\n",
            "Train loss: 2.077427625656128\n",
            "\n",
            "Time (s): 0.5095562934875488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 134 / 480\n",
            "LR: 0.00040120193984906366\n",
            "Train loss: 2.5663187503814697\n",
            "\n",
            "Time (s): 0.509835958480835\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 135 / 480\n",
            "LR: 0.00040118540873222897\n",
            "Train loss: 2.2003440856933594\n",
            "\n",
            "Time (s): 0.5095531940460205\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 136 / 480\n",
            "LR: 0.0004011688796586694\n",
            "Train loss: 2.3413710594177246\n",
            "\n",
            "Time (s): 0.5073206424713135\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 137 / 480\n",
            "LR: 0.0004011523526279639\n",
            "Train loss: 2.1740524768829346\n",
            "\n",
            "Time (s): 0.5117373466491699\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 138 / 480\n",
            "LR: 0.00040113582763969186\n",
            "Train loss: 2.210792064666748\n",
            "\n",
            "Time (s): 0.5061612129211426\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 139 / 480\n",
            "LR: 0.0004011193046934326\n",
            "Train loss: 2.190016508102417\n",
            "\n",
            "Time (s): 0.5121073722839355\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 140 / 480\n",
            "LR: 0.0004011027837887655\n",
            "Train loss: 2.2353217601776123\n",
            "\n",
            "Time (s): 0.5113234519958496\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 141 / 480\n",
            "LR: 0.0004010862649252703\n",
            "Train loss: 2.3125524520874023\n",
            "\n",
            "Time (s): 0.509662389755249\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 142 / 480\n",
            "LR: 0.00040106974810252664\n",
            "Train loss: 2.1131513118743896\n",
            "\n",
            "Time (s): 0.5072982311248779\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 143 / 480\n",
            "LR: 0.0004010532333201144\n",
            "Train loss: 2.209045648574829\n",
            "\n",
            "Time (s): 0.507739782333374\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 144 / 480\n",
            "LR: 0.00040103672057761354\n",
            "Train loss: 2.038790225982666\n",
            "\n",
            "Time (s): 0.5070233345031738\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 145 / 480\n",
            "LR: 0.0004010202098746041\n",
            "Train loss: 2.3313441276550293\n",
            "\n",
            "Time (s): 0.5077495574951172\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 146 / 480\n",
            "LR: 0.00040100370121066634\n",
            "Train loss: 2.1573715209960938\n",
            "\n",
            "Time (s): 0.5112426280975342\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 147 / 480\n",
            "LR: 0.0004009871945853805\n",
            "Train loss: 1.9502183198928833\n",
            "\n",
            "Time (s): 0.5059692859649658\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 148 / 480\n",
            "LR: 0.00040097068999832714\n",
            "Train loss: 2.283456325531006\n",
            "\n",
            "Time (s): 0.5063157081604004\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 149 / 480\n",
            "LR: 0.0004009541874490868\n",
            "Train loss: 2.155123233795166\n",
            "\n",
            "Time (s): 0.5122454166412354\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 150 / 480\n",
            "LR: 0.0004009376869372401\n",
            "Train loss: 2.1552226543426514\n",
            "\n",
            "Time (s): 0.5253310203552246\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 151 / 480\n",
            "LR: 0.00040092118846236783\n",
            "Train loss: 2.1150574684143066\n",
            "\n",
            "Time (s): 0.5288269519805908\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 152 / 480\n",
            "LR: 0.00040090469202405107\n",
            "Train loss: 2.1165990829467773\n",
            "\n",
            "Time (s): 0.5250039100646973\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 153 / 480\n",
            "LR: 0.00040088819762187076\n",
            "Train loss: 2.0480828285217285\n",
            "\n",
            "Time (s): 0.5271389484405518\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 154 / 480\n",
            "LR: 0.000400871705255408\n",
            "Train loss: 2.2621240615844727\n",
            "\n",
            "Time (s): 0.5289199352264404\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 155 / 480\n",
            "LR: 0.0004008552149242443\n",
            "Train loss: 2.3387157917022705\n",
            "\n",
            "Time (s): 0.5108091831207275\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 156 / 480\n",
            "LR: 0.00040083872662796097\n",
            "Train loss: 2.1457161903381348\n",
            "\n",
            "Time (s): 0.5296809673309326\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 157 / 480\n",
            "LR: 0.00040082224036613943\n",
            "Train loss: 2.162825584411621\n",
            "\n",
            "Time (s): 0.5091614723205566\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 158 / 480\n",
            "LR: 0.00040080575613836146\n",
            "Train loss: 2.4326446056365967\n",
            "\n",
            "Time (s): 0.5102629661560059\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 159 / 480\n",
            "LR: 0.00040078927394420876\n",
            "Train loss: 2.349571704864502\n",
            "\n",
            "Time (s): 0.509760856628418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 160 / 480\n",
            "LR: 0.00040077279378326327\n",
            "Train loss: 2.005887508392334\n",
            "\n",
            "Time (s): 0.5135669708251953\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 161 / 480\n",
            "LR: 0.000400756315655107\n",
            "Train loss: 2.243696689605713\n",
            "\n",
            "Time (s): 0.5054664611816406\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 162 / 480\n",
            "LR: 0.0004007398395593221\n",
            "Train loss: 2.2609572410583496\n",
            "\n",
            "Time (s): 0.519791841506958\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 163 / 480\n",
            "LR: 0.0004007233654954908\n",
            "Train loss: 2.3178250789642334\n",
            "\n",
            "Time (s): 0.5100696086883545\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 164 / 480\n",
            "LR: 0.00040070689346319543\n",
            "Train loss: 2.4037790298461914\n",
            "\n",
            "Time (s): 0.5139002799987793\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 165 / 480\n",
            "LR: 0.00040069042346201864\n",
            "Train loss: 2.1848254203796387\n",
            "\n",
            "Time (s): 0.5137968063354492\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 166 / 480\n",
            "LR: 0.00040067395549154287\n",
            "Train loss: 2.3083391189575195\n",
            "\n",
            "Time (s): 0.5102231502532959\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 167 / 480\n",
            "LR: 0.00040065748955135086\n",
            "Train loss: 2.104206085205078\n",
            "\n",
            "Time (s): 0.5051610469818115\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 168 / 480\n",
            "LR: 0.00040064102564102563\n",
            "Train loss: 2.330106735229492\n",
            "\n",
            "Time (s): 0.5073959827423096\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 169 / 480\n",
            "LR: 0.00040062456376015003\n",
            "Train loss: 2.2390005588531494\n",
            "\n",
            "Time (s): 0.5099225044250488\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 170 / 480\n",
            "LR: 0.0004006081039083071\n",
            "Train loss: 2.2491202354431152\n",
            "\n",
            "Time (s): 0.513800859451294\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 171 / 480\n",
            "LR: 0.00040059164608508024\n",
            "Train loss: 2.07277512550354\n",
            "\n",
            "Time (s): 0.5183665752410889\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 172 / 480\n",
            "LR: 0.00040057519029005267\n",
            "Train loss: 2.219665765762329\n",
            "\n",
            "Time (s): 0.5103707313537598\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 173 / 480\n",
            "LR: 0.0004005587365228079\n",
            "Train loss: 2.3410751819610596\n",
            "\n",
            "Time (s): 0.506589412689209\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 174 / 480\n",
            "LR: 0.0004005422847829294\n",
            "Train loss: 2.270024538040161\n",
            "\n",
            "Time (s): 0.5064113140106201\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 175 / 480\n",
            "LR: 0.0004005258350700008\n",
            "Train loss: 1.8963382244110107\n",
            "\n",
            "Time (s): 0.5062625408172607\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 176 / 480\n",
            "LR: 0.0004005093873836062\n",
            "Train loss: 2.1066341400146484\n",
            "\n",
            "Time (s): 0.5153446197509766\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 177 / 480\n",
            "LR: 0.0004004929417233294\n",
            "Train loss: 2.2555935382843018\n",
            "\n",
            "Time (s): 0.5164346694946289\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 178 / 480\n",
            "LR: 0.0004004764980887543\n",
            "Train loss: 2.073434591293335\n",
            "\n",
            "Time (s): 0.5204408168792725\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 179 / 480\n",
            "LR: 0.0004004600564794653\n",
            "Train loss: 2.2323179244995117\n",
            "\n",
            "Time (s): 0.5216481685638428\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 180 / 480\n",
            "LR: 0.0004004436168950466\n",
            "Train loss: 2.316645383834839\n",
            "\n",
            "Time (s): 0.5219683647155762\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 181 / 480\n",
            "LR: 0.00040042717933508256\n",
            "Train loss: 2.074207305908203\n",
            "\n",
            "Time (s): 0.5136377811431885\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 182 / 480\n",
            "LR: 0.00040041074379915776\n",
            "Train loss: 1.97600519657135\n",
            "\n",
            "Time (s): 0.5172934532165527\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 183 / 480\n",
            "LR: 0.0004003943102868568\n",
            "Train loss: 2.178311347961426\n",
            "\n",
            "Time (s): 0.5173335075378418\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 184 / 480\n",
            "LR: 0.00040037787879776453\n",
            "Train loss: 2.345545768737793\n",
            "\n",
            "Time (s): 0.5143587589263916\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 185 / 480\n",
            "LR: 0.0004003614493314659\n",
            "Train loss: 2.305361032485962\n",
            "\n",
            "Time (s): 0.5065605640411377\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 186 / 480\n",
            "LR: 0.0004003450218875458\n",
            "Train loss: 2.085620403289795\n",
            "\n",
            "Time (s): 0.5074505805969238\n",
            "=========================\n",
            "\n",
            "=========================\n",
            "Epoch 26  Batch 187 / 480\n",
            "LR: 0.00040032859646558925\n",
            "Train loss: 2.100720167160034\n",
            "\n",
            "Time (s): 0.5043416023254395\n",
            "=========================\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Updated-Music-Transformer/train.py\", line 222, in <module>\n",
            "    main()\n",
            "  File \"/content/Updated-Music-Transformer/train.py\", line 150, in main\n",
            "    train_epoch(epoch+1, model, train_loader, train_loss_func, opt, lr_scheduler, args.print_modulus)\n",
            "  File \"/content/Updated-Music-Transformer/utilities/run_model.py\", line 38, in train_epoch\n",
            "    out.backward()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\", line 488, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss e Accuracy"
      ],
      "metadata": {
        "id": "HWLpfe-bmNWM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VsWgRDNJmPiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Music generation and evaluation"
      ],
      "metadata": {
        "id": "9-JMkQQ8GpbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generated 100 pieces from 5 original database files\n",
        "(Output files saved in Google Drive)"
      ],
      "metadata": {
        "id": "0IqJseNbic7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 generate_multiple.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27OVcek_utFn",
        "outputId": "3d1de2c3-1c72-47d9-e057-9c20e18f5cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 390\n",
            "usage: generate_multiple.py\n",
            "       [-h]\n",
            "       [-midi_root MIDI_ROOT]\n",
            "       [-output_dir OUTPUT_DIR]\n",
            "       [-primer_file PRIMER_FILE]\n",
            "       [-num_primer_files NUM_PRIMER_FILES]\n",
            "       [--force_cpu]\n",
            "       [-target_seq_length TARGET_SEQ_LENGTH]\n",
            "       [-num_prime NUM_PRIME]\n",
            "       [-model_weights MODEL_WEIGHTS]\n",
            "       [-beam BEAM]\n",
            "       [--rpr]\n",
            "       [--pmp]\n",
            "       [-max_sequence MAX_SEQUENCE]\n",
            "       [-n_layers N_LAYERS]\n",
            "       [-num_heads NUM_HEADS]\n",
            "       [-d_model D_MODEL]\n",
            "       [-dim_feedforward DIM_FEEDFORWARD]\n",
            "       [-num_samples NUM_SAMPLES]\n",
            "       [--struct]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  -midi_root MIDI_ROOT\n",
            "    Midi file\n",
            "    to prime\n",
            "    the\n",
            "    generator\n",
            "    with\n",
            "  -output_dir OUTPUT_DIR\n",
            "    Folder to\n",
            "    write\n",
            "    generated\n",
            "    midi to\n",
            "  -primer_file PRIMER_FILE\n",
            "    File path\n",
            "    or integer\n",
            "    index to\n",
            "    the\n",
            "    evaluation\n",
            "    dataset.\n",
            "    Default is\n",
            "    to select a\n",
            "    random\n",
            "    index.\n",
            "  -num_primer_files NUM_PRIMER_FILES\n",
            "    Number of\n",
            "    files to\n",
            "    prime the\n",
            "    generator\n",
            "    with.\n",
            "    Indexes are\n",
            "    chosen at\n",
            "    random.\n",
            "  --force_cpu\n",
            "    Forces\n",
            "    model to\n",
            "    run on a\n",
            "    cpu even\n",
            "    when gpu is\n",
            "    available\n",
            "  -target_seq_length TARGET_SEQ_LENGTH\n",
            "    Target\n",
            "    length\n",
            "    you'd like\n",
            "    the midi to\n",
            "    be\n",
            "  -num_prime NUM_PRIME\n",
            "    Amount of\n",
            "    messages to\n",
            "    prime the\n",
            "    generator\n",
            "    with\n",
            "  -model_weights MODEL_WEIGHTS\n",
            "    Pickled\n",
            "    model\n",
            "    weights\n",
            "    file saved\n",
            "    with\n",
            "    torch.save\n",
            "    and model.s\n",
            "    tate_dict()\n",
            "  -beam BEAM\n",
            "    Beam search\n",
            "    k. 0 for\n",
            "    random\n",
            "    probability\n",
            "    sample and\n",
            "    1 for\n",
            "    greedy\n",
            "  --rpr\n",
            "    Use a\n",
            "    modified\n",
            "    Transformer\n",
            "    for\n",
            "    Relative\n",
            "    Position Re\n",
            "    presentatio\n",
            "    ns\n",
            "  --pmp\n",
            "    Use the\n",
            "    Pan-Matrix\n",
            "    Profile in\n",
            "    the model\n",
            "  -max_sequence MAX_SEQUENCE\n",
            "    Maximum\n",
            "    midi\n",
            "    sequence to\n",
            "    consider\n",
            "  -n_layers N_LAYERS\n",
            "    Number of\n",
            "    decoder\n",
            "    layers to\n",
            "    use\n",
            "  -num_heads NUM_HEADS\n",
            "    Number of\n",
            "    heads to\n",
            "    use for\n",
            "    multi-head\n",
            "    attention\n",
            "  -d_model D_MODEL\n",
            "    Dimension\n",
            "    of the\n",
            "    model\n",
            "    (output dim\n",
            "    of\n",
            "    embedding\n",
            "    layers,\n",
            "    etc.)\n",
            "  -dim_feedforward DIM_FEEDFORWARD\n",
            "    Dimension\n",
            "    of the\n",
            "    feedforward\n",
            "    layer\n",
            "  -num_samples NUM_SAMPLES\n",
            "    Number of\n",
            "    samples to\n",
            "    be\n",
            "    generated\n",
            "    from one\n",
            "    midi file\n",
            "    in the\n",
            "    dataset\n",
            "  --struct\n",
            "    Calculate s\n",
            "    tructurenes\n",
            "    s\n",
            "    indicators\n",
            "    of the\n",
            "    generated\n",
            "    samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 generate_multiple.py -midi_root '../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro' -output_dir '../drive/MyDrive/Music Transformer/outputs/03' -target_seq_length 2048 -model_weights trained_models/maestro.pickle -num_primer_files 5 -num_samples 20 --rpr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y5nUEYOHQs8",
        "outputId": "f1d14b47-4c44-4317-dfa5-3f2fe9994681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 390\n",
            "=========================\n",
            "midi_root: ../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro\n",
            "output_dir: ../drive/MyDrive/Music Transformer/outputs/03\n",
            "primer_file: None\n",
            "force_cpu: False\n",
            "\n",
            "target_seq_length: 2048\n",
            "num_prime: 256\n",
            "model_weights: trained_models/maestro.pickle\n",
            "beam: 0\n",
            "\n",
            "rpr: True\n",
            "pmp: False\n",
            "max_sequence: 2048\n",
            "n_layers: 6\n",
            "num_heads: 8\n",
            "d_model: 512\n",
            "\n",
            "dim_feedforward: 1024\n",
            "=========================\n",
            "\n",
            "Using primer index: 154 ( ../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro/test/ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--4.pickle )\n",
            "Generating piece 154-0\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 86\n",
            "info removed pitch: 70\n",
            "info removed pitch: 52\n",
            "info removed pitch: 68\n",
            "info removed pitch: 33\n",
            "info removed pitch: 101\n",
            "info removed pitch: 54\n",
            "\n",
            "Generating piece 154-1\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 89\n",
            "info removed pitch: 52\n",
            "info removed pitch: 95\n",
            "info removed pitch: 93\n",
            "info removed pitch: 94\n",
            "info removed pitch: 81\n",
            "info removed pitch: 57\n",
            "info removed pitch: 65\n",
            "info removed pitch: 90\n",
            "info removed pitch: 69\n",
            "\n",
            "Generating piece 154-2\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 33\n",
            "info removed pitch: 33\n",
            "info removed pitch: 97\n",
            "info removed pitch: 98\n",
            "info removed pitch: 91\n",
            "info removed pitch: 97\n",
            "info removed pitch: 97\n",
            "\n",
            "Generating piece 154-3\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 90\n",
            "info removed pitch: 65\n",
            "info removed pitch: 91\n",
            "\n",
            "Generating piece 154-4\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 88\n",
            "info removed pitch: 86\n",
            "info removed pitch: 81\n",
            "info removed pitch: 68\n",
            "\n",
            "Generating piece 154-5\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 65\n",
            "info removed pitch: 74\n",
            "info removed pitch: 94\n",
            "info removed pitch: 96\n",
            "info removed pitch: 68\n",
            "info removed pitch: 96\n",
            "info removed pitch: 56\n",
            "\n",
            "Generating piece 154-6\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 86\n",
            "info removed pitch: 91\n",
            "info removed pitch: 32\n",
            "info removed pitch: 64\n",
            "\n",
            "Generating piece 154-7\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 35\n",
            "info removed pitch: 54\n",
            "info removed pitch: 68\n",
            "info removed pitch: 37\n",
            "info removed pitch: 61\n",
            "\n",
            "Generating piece 154-8\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 74\n",
            "info removed pitch: 77\n",
            "info removed pitch: 34\n",
            "\n",
            "Generating piece 154-9\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 54\n",
            "info removed pitch: 23\n",
            "info removed pitch: 85\n",
            "info removed pitch: 93\n",
            "info removed pitch: 68\n",
            "\n",
            "Generating piece 154-10\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 92\n",
            "info removed pitch: 52\n",
            "info removed pitch: 47\n",
            "info removed pitch: 54\n",
            "info removed pitch: 92\n",
            "info removed pitch: 92\n",
            "info removed pitch: 35\n",
            "info removed pitch: 91\n",
            "info removed pitch: 42\n",
            "\n",
            "Generating piece 154-11\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 44\n",
            "info removed pitch: 83\n",
            "info removed pitch: 86\n",
            "info removed pitch: 25\n",
            "info removed pitch: 92\n",
            "\n",
            "Generating piece 154-12\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 83\n",
            "info removed pitch: 78\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 101\n",
            "info removed pitch: 98\n",
            "info removed pitch: 88\n",
            "info removed pitch: 32\n",
            "\n",
            "Generating piece 154-13\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 57\n",
            "info removed pitch: 66\n",
            "info removed pitch: 70\n",
            "info removed pitch: 83\n",
            "info removed pitch: 58\n",
            "info removed pitch: 86\n",
            "info removed pitch: 99\n",
            "info removed pitch: 34\n",
            "\n",
            "Generating piece 154-14\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 42\n",
            "info removed pitch: 76\n",
            "info removed pitch: 92\n",
            "info removed pitch: 94\n",
            "info removed pitch: 42\n",
            "info removed pitch: 85\n",
            "info removed pitch: 85\n",
            "info removed pitch: 97\n",
            "\n",
            "Generating piece 154-15\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 68\n",
            "info removed pitch: 56\n",
            "info removed pitch: 94\n",
            "\n",
            "Generating piece 154-16\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 28\n",
            "info removed pitch: 100\n",
            "\n",
            "Generating piece 154-17\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 94\n",
            "info removed pitch: 49\n",
            "info removed pitch: 49\n",
            "info removed pitch: 30\n",
            "\n",
            "Generating piece 154-18\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 47\n",
            "info removed pitch: 69\n",
            "info removed pitch: 70\n",
            "info removed pitch: 45\n",
            "info removed pitch: 69\n",
            "info removed pitch: 83\n",
            "info removed pitch: 86\n",
            "info removed pitch: 49\n",
            "info removed pitch: 88\n",
            "info removed pitch: 93\n",
            "info removed pitch: 30\n",
            "info removed pitch: 32\n",
            "\n",
            "Generating piece 154-19\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 56\n",
            "info removed pitch: 86\n",
            "info removed pitch: 85\n",
            "\n",
            "Using primer index: 85 ( ../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro/test/MIDI-Unprocessed_16_R2_2009_01_ORIG_MID--AUDIO_16_R2_2009_16_R2_2009_01_WAV.pickle )\n",
            "Generating piece 85-0\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 66\n",
            "info removed pitch: 37\n",
            "\n",
            "Generating piece 85-1\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 56\n",
            "info removed pitch: 77\n",
            "info removed pitch: 84\n",
            "\n",
            "Generating piece 85-2\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 46\n",
            "info removed pitch: 54\n",
            "info removed pitch: 82\n",
            "\n",
            "Generating piece 85-3\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 75\n",
            "info removed pitch: 86\n",
            "\n",
            "Generating piece 85-4\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 83\n",
            "info removed pitch: 61\n",
            "\n",
            "Generating piece 85-5\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 88\n",
            "info removed pitch: 58\n",
            "info removed pitch: 46\n",
            "info removed pitch: 58\n",
            "info removed pitch: 46\n",
            "info removed pitch: 58\n",
            "info removed pitch: 46\n",
            "info removed pitch: 46\n",
            "info removed pitch: 46\n",
            "info removed pitch: 46\n",
            "info removed pitch: 46\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 96\n",
            "info removed pitch: 96\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 84\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 91\n",
            "info removed pitch: 79\n",
            "info removed pitch: 77\n",
            "info removed pitch: 77\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "\n",
            "Generating piece 85-6\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 85-7\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 49\n",
            "info removed pitch: 84\n",
            "info removed pitch: 86\n",
            "info removed pitch: 66\n",
            "info removed pitch: 41\n",
            "info removed pitch: 89\n",
            "info removed pitch: 91\n",
            "info removed pitch: 102\n",
            "info removed pitch: 93\n",
            "info removed pitch: 94\n",
            "info removed pitch: 89\n",
            "\n",
            "Generating piece 85-8\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 91\n",
            "info removed pitch: 83\n",
            "info removed pitch: 33\n",
            "info removed pitch: 93\n",
            "info removed pitch: 93\n",
            "info removed pitch: 93\n",
            "\n",
            "Generating piece 85-9\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 95\n",
            "\n",
            "Generating piece 85-10\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 88\n",
            "info removed pitch: 50\n",
            "\n",
            "Generating piece 85-11\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 58\n",
            "info removed pitch: 44\n",
            "info removed pitch: 84\n",
            "info removed pitch: 80\n",
            "info removed pitch: 97\n",
            "info removed pitch: 88\n",
            "info removed pitch: 95\n",
            "info removed pitch: 95\n",
            "info removed pitch: 95\n",
            "info removed pitch: 95\n",
            "info removed pitch: 93\n",
            "info removed pitch: 95\n",
            "info removed pitch: 95\n",
            "info removed pitch: 51\n",
            "\n",
            "Generating piece 85-12\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 33\n",
            "info removed pitch: 68\n",
            "info removed pitch: 33\n",
            "info removed pitch: 95\n",
            "info removed pitch: 87\n",
            "info removed pitch: 87\n",
            "info removed pitch: 87\n",
            "\n",
            "Generating piece 85-13\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 85-14\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 50\n",
            "info removed pitch: 93\n",
            "info removed pitch: 38\n",
            "info removed pitch: 49\n",
            "\n",
            "Generating piece 85-15\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 54\n",
            "info removed pitch: 49\n",
            "\n",
            "Generating piece 85-16\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 24\n",
            "\n",
            "Generating piece 85-17\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 53\n",
            "info removed pitch: 85\n",
            "info removed pitch: 83\n",
            "info removed pitch: 72\n",
            "\n",
            "Generating piece 85-18\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 100\n",
            "\n",
            "Generating piece 85-19\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 37\n",
            "\n",
            "Using primer index: 26 ( ../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro/test/MIDI-Unprocessed_06_R1_2008_01-04_ORIG_MID--AUDIO_06_R1_2008_wav--3.pickle )\n",
            "Generating piece 26-0\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 74\n",
            "info removed pitch: 34\n",
            "info removed pitch: 64\n",
            "info removed pitch: 43\n",
            "info removed pitch: 36\n",
            "info removed pitch: 31\n",
            "info removed pitch: 29\n",
            "\n",
            "Generating piece 26-1\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 39\n",
            "info removed pitch: 89\n",
            "info removed pitch: 97\n",
            "info removed pitch: 86\n",
            "info removed pitch: 93\n",
            "info removed pitch: 89\n",
            "info removed pitch: 40\n",
            "info removed pitch: 74\n",
            "info removed pitch: 32\n",
            "\n",
            "Generating piece 26-2\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 70\n",
            "\n",
            "Generating piece 26-3\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 26-4\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 82\n",
            "info removed pitch: 39\n",
            "info removed pitch: 96\n",
            "info removed pitch: 43\n",
            "info removed pitch: 39\n",
            "info removed pitch: 57\n",
            "\n",
            "Generating piece 26-5\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 89\n",
            "info removed pitch: 58\n",
            "info removed pitch: 96\n",
            "info removed pitch: 71\n",
            "info removed pitch: 81\n",
            "\n",
            "Generating piece 26-6\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 54\n",
            "info removed pitch: 84\n",
            "info removed pitch: 91\n",
            "info removed pitch: 35\n",
            "info removed pitch: 76\n",
            "\n",
            "Generating piece 26-7\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 89\n",
            "info removed pitch: 43\n",
            "info removed pitch: 86\n",
            "info removed pitch: 40\n",
            "info removed pitch: 83\n",
            "\n",
            "Generating piece 26-8\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 53\n",
            "info removed pitch: 74\n",
            "info removed pitch: 31\n",
            "info removed pitch: 87\n",
            "info removed pitch: 87\n",
            "info removed pitch: 89\n",
            "\n",
            "Generating piece 26-9\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 57\n",
            "info removed pitch: 91\n",
            "info removed pitch: 37\n",
            "info removed pitch: 30\n",
            "info removed pitch: 36\n",
            "info removed pitch: 87\n",
            "info removed pitch: 33\n",
            "info removed pitch: 27\n",
            "\n",
            "Generating piece 26-10\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 53\n",
            "info removed pitch: 99\n",
            "info removed pitch: 60\n",
            "info removed pitch: 32\n",
            "\n",
            "Generating piece 26-11\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 54\n",
            "info removed pitch: 86\n",
            "\n",
            "Generating piece 26-12\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 54\n",
            "info removed pitch: 48\n",
            "info removed pitch: 57\n",
            "\n",
            "Generating piece 26-13\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 64\n",
            "info removed pitch: 76\n",
            "info removed pitch: 86\n",
            "info removed pitch: 89\n",
            "info removed pitch: 82\n",
            "\n",
            "Generating piece 26-14\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 105\n",
            "info removed pitch: 54\n",
            "info removed pitch: 29\n",
            "info removed pitch: 85\n",
            "info removed pitch: 100\n",
            "info removed pitch: 99\n",
            "info removed pitch: 56\n",
            "info removed pitch: 32\n",
            "info removed pitch: 96\n",
            "info removed pitch: 56\n",
            "info removed pitch: 99\n",
            "\n",
            "Generating piece 26-15\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 96\n",
            "info removed pitch: 34\n",
            "info removed pitch: 32\n",
            "info removed pitch: 54\n",
            "info removed pitch: 64\n",
            "info removed pitch: 45\n",
            "info removed pitch: 86\n",
            "info removed pitch: 86\n",
            "\n",
            "Generating piece 26-16\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 40\n",
            "info removed pitch: 89\n",
            "\n",
            "Generating piece 26-17\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 26-18\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 79\n",
            "info removed pitch: 69\n",
            "info removed pitch: 73\n",
            "\n",
            "Generating piece 26-19\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 48\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 79\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 82\n",
            "info removed pitch: 94\n",
            "info removed pitch: 82\n",
            "info removed pitch: 34\n",
            "\n",
            "Using primer index: 96 ( ../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro/test/MIDI-Unprocessed_24_R1_2011_MID--AUDIO_R1-D9_11_Track11_wav.pickle )\n",
            "Generating piece 96-0\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 96-1\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 43\n",
            "info removed pitch: 53\n",
            "info removed pitch: 36\n",
            "info removed pitch: 85\n",
            "info removed pitch: 32\n",
            "\n",
            "Generating piece 96-2\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 87\n",
            "info removed pitch: 36\n",
            "info removed pitch: 32\n",
            "\n",
            "Generating piece 96-3\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 50\n",
            "\n",
            "Generating piece 96-4\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 89\n",
            "info removed pitch: 82\n",
            "info removed pitch: 43\n",
            "\n",
            "Generating piece 96-5\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 82\n",
            "info removed pitch: 53\n",
            "info removed pitch: 87\n",
            "info removed pitch: 76\n",
            "info removed pitch: 95\n",
            "info removed pitch: 83\n",
            "info removed pitch: 95\n",
            "info removed pitch: 69\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "info removed pitch: 40\n",
            "\n",
            "Generating piece 96-6\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 59\n",
            "info removed pitch: 63\n",
            "info removed pitch: 57\n",
            "info removed pitch: 74\n",
            "info removed pitch: 45\n",
            "info removed pitch: 94\n",
            "info removed pitch: 96\n",
            "\n",
            "Generating piece 96-7\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 93\n",
            "info removed pitch: 39\n",
            "info removed pitch: 23\n",
            "info removed pitch: 28\n",
            "info removed pitch: 90\n",
            "info removed pitch: 96\n",
            "info removed pitch: 93\n",
            "\n",
            "Generating piece 96-8\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 87\n",
            "info removed pitch: 96\n",
            "info removed pitch: 95\n",
            "info removed pitch: 71\n",
            "\n",
            "Generating piece 96-9\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 96-10\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 32\n",
            "info removed pitch: 88\n",
            "\n",
            "Generating piece 96-11\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 96-12\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 29\n",
            "info removed pitch: 38\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 87\n",
            "info removed pitch: 103\n",
            "\n",
            "Generating piece 96-13\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 46\n",
            "info removed pitch: 107\n",
            "\n",
            "Generating piece 96-14\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 49\n",
            "info removed pitch: 46\n",
            "info removed pitch: 84\n",
            "info removed pitch: 52\n",
            "info removed pitch: 49\n",
            "info removed pitch: 66\n",
            "info removed pitch: 49\n",
            "info removed pitch: 85\n",
            "\n",
            "Generating piece 96-15\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 96-16\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 88\n",
            "info removed pitch: 88\n",
            "\n",
            "Generating piece 96-17\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 86\n",
            "\n",
            "Generating piece 96-18\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 89\n",
            "info removed pitch: 32\n",
            "info removed pitch: 51\n",
            "info removed pitch: 87\n",
            "\n",
            "Generating piece 96-19\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Using primer index: 90 ( ../drive/MyDrive/Music Transformer/MusicTransformer-Pytorch-new_notation/e_piano_maestro/test/MIDI-Unprocessed_17_R1_2006_01-06_ORIG_MID--AUDIO_17_R1_2006_02_Track02_wav.pickle )\n",
            "Generating piece 90-0\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 50\n",
            "info removed pitch: 36\n",
            "info removed pitch: 91\n",
            "info removed pitch: 34\n",
            "info removed pitch: 39\n",
            "\n",
            "Generating piece 90-1\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 50\n",
            "info removed pitch: 50\n",
            "info removed pitch: 31\n",
            "\n",
            "Generating piece 90-2\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 46\n",
            "info removed pitch: 46\n",
            "info removed pitch: 36\n",
            "info removed pitch: 77\n",
            "info removed pitch: 72\n",
            "\n",
            "Generating piece 90-3\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 46\n",
            "info removed pitch: 91\n",
            "info removed pitch: 82\n",
            "info removed pitch: 38\n",
            "\n",
            "Generating piece 90-4\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "\n",
            "Generating piece 90-5\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 92\n",
            "info removed pitch: 70\n",
            "\n",
            "Generating piece 90-6\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 25\n",
            "info removed pitch: 98\n",
            "info removed pitch: 39\n",
            "info removed pitch: 72\n",
            "info removed pitch: 27\n",
            "info removed pitch: 34\n",
            "\n",
            "Generating piece 90-7\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 98\n",
            "info removed pitch: 93\n",
            "info removed pitch: 93\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 93\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 94\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "info removed pitch: 102\n",
            "\n",
            "Generating piece 90-8\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 31\n",
            "info removed pitch: 55\n",
            "info removed pitch: 92\n",
            "\n",
            "Generating piece 90-9\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 91\n",
            "info removed pitch: 41\n",
            "info removed pitch: 25\n",
            "info removed pitch: 46\n",
            "info removed pitch: 43\n",
            "info removed pitch: 92\n",
            "\n",
            "Generating piece 90-10\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 80\n",
            "info removed pitch: 84\n",
            "\n",
            "Generating piece 90-11\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 39\n",
            "info removed pitch: 48\n",
            "info removed pitch: 24\n",
            "info removed pitch: 34\n",
            "info removed pitch: 89\n",
            "\n",
            "Generating piece 90-12\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 60\n",
            "info removed pitch: 92\n",
            "\n",
            "Generating piece 90-13\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 94\n",
            "info removed pitch: 92\n",
            "info removed pitch: 72\n",
            "\n",
            "Generating piece 90-14\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 43\n",
            "info removed pitch: 77\n",
            "info removed pitch: 41\n",
            "info removed pitch: 53\n",
            "info removed pitch: 72\n",
            "info removed pitch: 65\n",
            "info removed pitch: 70\n",
            "\n",
            "Generating piece 90-15\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 23\n",
            "info removed pitch: 82\n",
            "info removed pitch: 37\n",
            "info removed pitch: 82\n",
            "info removed pitch: 43\n",
            "info removed pitch: 48\n",
            "\n",
            "Generating piece 90-16\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 28\n",
            "info removed pitch: 50\n",
            "info removed pitch: 77\n",
            "\n",
            "Generating piece 90-17\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 46\n",
            "info removed pitch: 49\n",
            "info removed pitch: 39\n",
            "info removed pitch: 72\n",
            "\n",
            "Generating piece 90-18\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 43\n",
            "\n",
            "Generating piece 90-19\n",
            "RAND DIST\n",
            "Generating sequence of max length: 2048\n",
            "300 / 2048\n",
            "350 / 2048\n",
            "400 / 2048\n",
            "450 / 2048\n",
            "500 / 2048\n",
            "550 / 2048\n",
            "600 / 2048\n",
            "650 / 2048\n",
            "700 / 2048\n",
            "750 / 2048\n",
            "800 / 2048\n",
            "850 / 2048\n",
            "900 / 2048\n",
            "950 / 2048\n",
            "1000 / 2048\n",
            "1050 / 2048\n",
            "1100 / 2048\n",
            "1150 / 2048\n",
            "1200 / 2048\n",
            "1250 / 2048\n",
            "1300 / 2048\n",
            "1350 / 2048\n",
            "1400 / 2048\n",
            "1450 / 2048\n",
            "1500 / 2048\n",
            "1550 / 2048\n",
            "1600 / 2048\n",
            "1650 / 2048\n",
            "1700 / 2048\n",
            "1750 / 2048\n",
            "1800 / 2048\n",
            "1850 / 2048\n",
            "1900 / 2048\n",
            "1950 / 2048\n",
            "2000 / 2048\n",
            "info removed pitch: 55\n",
            "info removed pitch: 84\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pitch Class Histogram Entropy\n",
        "(Jazz Transformer)"
      ],
      "metadata": {
        "id": "kF73Y66Cirak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 pitch_class_entropy.py -h"
      ],
      "metadata": {
        "id": "o7I2MSs5R7bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06578354-2295-4844-83c8-13520681856d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: pitch_class_entropy.py\n",
            "       [-h]\n",
            "       [-midi_root MIDI_ROOT]\n",
            "       [--print_each]\n",
            "       [-n_resamples N_RESAMPLES]\n",
            "       [-confidence_level CONFIDENCE_LEVEL]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  -midi_root MIDI_ROOT\n",
            "    Folder of\n",
            "    midi files\n",
            "    to be\n",
            "    evaluated.\n",
            "  --print_each\n",
            "    Print\n",
            "    entropy\n",
            "    value of\n",
            "    each piece.\n",
            "  -n_resamples N_RESAMPLES\n",
            "    Number of\n",
            "    resamples\n",
            "    for the\n",
            "    bootstrap\n",
            "    method.\n",
            "  -confidence_level CONFIDENCE_LEVEL\n",
            "    Confidence\n",
            "    level for\n",
            "    the\n",
            "    confidence\n",
            "    interval.\n",
            "    Default:\n",
            "    0.95.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! python3 pitch_class_entropy.py -midi_root '../drive/MyDrive/Music Transformer/outputs/03' -n_resamples 9999 -confidence_level 0.95 --print_each"
      ],
      "metadata": {
        "id": "vTMouoB1tAou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6efa5c9a-7502-4ac9-f2cd-432d68a6f135"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pitch Class Histogram Entropy\n",
            "MIDI directory: ../drive/MyDrive/Music Transformer/outputs/03\n",
            "\n",
            "-----Original pieces-----\n",
            "original-154.mid\tentropy: 3.3222826860483075\n",
            "original-26.mid\tentropy: 3.1901821150145047\n",
            "original-85.mid\tentropy: 3.383766664450279\n",
            "original-90.mid\tentropy: 3.3034120991890195\n",
            "original-96.mid\tentropy: 3.0959085494065652\n",
            "Mean entropy:\t3.2591104228217347\n",
            "Mean entropy confidence interval:\tConfidenceInterval(low=3.156263972484644, high=3.335514711766859)\n",
            "\n",
            "-----Generated pieces-----\n",
            "rand-154-0.mid\tentropy: 2.985294395454004\n",
            "rand-154-1.mid\tentropy: 2.6234653848131653\n",
            "rand-154-10.mid\tentropy: 3.194998725652757\n",
            "rand-154-11.mid\tentropy: 3.286051231174733\n",
            "rand-154-12.mid\tentropy: 3.1631846935557415\n",
            "rand-154-13.mid\tentropy: 3.130536284036885\n",
            "rand-154-14.mid\tentropy: 3.223138591865338\n",
            "rand-154-15.mid\tentropy: 3.366984475150055\n",
            "rand-154-16.mid\tentropy: 2.950811651353105\n",
            "rand-154-17.mid\tentropy: 3.3104902227907758\n",
            "rand-154-18.mid\tentropy: 3.229041037897061\n",
            "rand-154-19.mid\tentropy: 2.6914999208786465\n",
            "rand-154-2.mid\tentropy: 3.2896901894386814\n",
            "rand-154-3.mid\tentropy: 3.1957367563082633\n",
            "rand-154-4.mid\tentropy: 3.046550010628715\n",
            "rand-154-5.mid\tentropy: 3.040115434060637\n",
            "rand-154-6.mid\tentropy: 2.9452090631554477\n",
            "rand-154-7.mid\tentropy: 2.752436038936784\n",
            "rand-154-8.mid\tentropy: 2.9394954750217956\n",
            "rand-154-9.mid\tentropy: 3.250563926971658\n",
            "rand-26-0.mid\tentropy: 3.358081493888299\n",
            "rand-26-1.mid\tentropy: 3.388515371932708\n",
            "rand-26-10.mid\tentropy: 2.919890987587646\n",
            "rand-26-11.mid\tentropy: 3.0776491745438737\n",
            "rand-26-12.mid\tentropy: 3.04912344325972\n",
            "rand-26-13.mid\tentropy: 3.240487762335335\n",
            "rand-26-14.mid\tentropy: 3.4468041669456593\n",
            "rand-26-15.mid\tentropy: 3.1794308855187685\n",
            "rand-26-16.mid\tentropy: 3.160973254684332\n",
            "rand-26-17.mid\tentropy: 3.028952749913246\n",
            "rand-26-18.mid\tentropy: 2.710843085806767\n",
            "rand-26-19.mid\tentropy: 2.5245261258892215\n",
            "rand-26-2.mid\tentropy: 3.042284564977497\n",
            "rand-26-3.mid\tentropy: 2.862426656925759\n",
            "rand-26-4.mid\tentropy: 2.833745423737583\n",
            "rand-26-5.mid\tentropy: 3.29233279779764\n",
            "rand-26-6.mid\tentropy: 3.2609276328186088\n",
            "rand-26-7.mid\tentropy: 3.2674835296862756\n",
            "rand-26-8.mid\tentropy: 3.447733946191866\n",
            "rand-26-9.mid\tentropy: 3.5519528313261692\n",
            "rand-85-0.mid\tentropy: 3.370494570026173\n",
            "rand-85-1.mid\tentropy: 2.7725730723509074\n",
            "rand-85-10.mid\tentropy: 3.1959552564843543\n",
            "rand-85-11.mid\tentropy: 2.76771484247648\n",
            "rand-85-12.mid\tentropy: 3.1611672828440156\n",
            "rand-85-13.mid\tentropy: 2.7904387258989996\n",
            "rand-85-14.mid\tentropy: 2.3186564523958366\n",
            "rand-85-15.mid\tentropy: 3.1556847720755776\n",
            "rand-85-16.mid\tentropy: 3.4396019081703084\n",
            "rand-85-17.mid\tentropy: 3.172151497489646\n",
            "rand-85-18.mid\tentropy: 3.194937292274311\n",
            "rand-85-19.mid\tentropy: 2.613703563871233\n",
            "rand-85-2.mid\tentropy: 3.0210762315512465\n",
            "rand-85-3.mid\tentropy: 3.3242235483364104\n",
            "rand-85-4.mid\tentropy: 2.9996488899398464\n",
            "rand-85-5.mid\tentropy: 2.9398204235807124\n",
            "rand-85-6.mid\tentropy: 2.0717715136150145\n",
            "rand-85-7.mid\tentropy: 3.361085445816278\n",
            "rand-85-8.mid\tentropy: 3.2171808272479683\n",
            "rand-85-9.mid\tentropy: 2.980156032778442\n",
            "rand-90-0.mid\tentropy: 3.20393182783654\n",
            "rand-90-1.mid\tentropy: 3.169543546136687\n",
            "rand-90-10.mid\tentropy: 3.295778103745262\n",
            "rand-90-11.mid\tentropy: 3.2724733357471654\n",
            "rand-90-12.mid\tentropy: 3.180283514140987\n",
            "rand-90-13.mid\tentropy: 3.0888557154334113\n",
            "rand-90-14.mid\tentropy: 3.334665256922281\n",
            "rand-90-15.mid\tentropy: 3.334037610325987\n",
            "rand-90-16.mid\tentropy: 3.509279009270301\n",
            "rand-90-17.mid\tentropy: 3.1742346181321333\n",
            "rand-90-18.mid\tentropy: 3.4122840051053593\n",
            "rand-90-19.mid\tentropy: 3.471757622709438\n",
            "rand-90-2.mid\tentropy: 3.464155273151468\n",
            "rand-90-3.mid\tentropy: 3.352543216852417\n",
            "rand-90-4.mid\tentropy: 3.1016053801651697\n",
            "rand-90-5.mid\tentropy: 3.2514306141277123\n",
            "rand-90-6.mid\tentropy: 3.2240034286900485\n",
            "rand-90-7.mid\tentropy: 2.0399909360218604\n",
            "rand-90-8.mid\tentropy: 3.3496426875348226\n",
            "rand-90-9.mid\tentropy: 3.3228455725309773\n",
            "rand-96-0.mid\tentropy: 2.5480193391742647\n",
            "rand-96-1.mid\tentropy: 2.9369393471047753\n",
            "rand-96-10.mid\tentropy: 3.120308146808771\n",
            "rand-96-11.mid\tentropy: 2.7655843009171663\n",
            "rand-96-12.mid\tentropy: 2.868859928621735\n",
            "rand-96-13.mid\tentropy: 2.561769251175559\n",
            "rand-96-14.mid\tentropy: 3.046347001284361\n",
            "rand-96-15.mid\tentropy: 3.127100554710119\n",
            "rand-96-16.mid\tentropy: 3.0692911254648085\n",
            "rand-96-17.mid\tentropy: 2.8041927754063183\n",
            "rand-96-18.mid\tentropy: 2.534459401724189\n",
            "rand-96-19.mid\tentropy: 2.784053868672979\n",
            "rand-96-2.mid\tentropy: 3.111515181072854\n",
            "rand-96-3.mid\tentropy: 2.6875028084282446\n",
            "rand-96-4.mid\tentropy: 3.302309391677155\n",
            "rand-96-5.mid\tentropy: 2.756130639039663\n",
            "rand-96-6.mid\tentropy: 3.195916387926548\n",
            "rand-96-7.mid\tentropy: 3.108376514704699\n",
            "rand-96-8.mid\tentropy: 3.259674342542342\n",
            "rand-96-9.mid\tentropy: 2.845209452946006\n",
            "Mean entropy:\t3.0711440257811757\n",
            "Mean entropy confidence interval:\tConfidenceInterval(low=3.0090595378391636, high=3.123975678480635)\n",
            "\n",
            "-----Mean entropy comparison-----\n",
            "Original: \t 3.2591104228217347 \t ConfidenceInterval(low=3.156263972484644, high=3.335514711766859)\n",
            "Generated: \t 3.0711440257811757 \t ConfidenceInterval(low=3.0090595378391636, high=3.123975678480635)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q2zcSt9WkKa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structureness Indicators\n",
        "(Jazz Transformer)"
      ],
      "metadata": {
        "id": "88wvVMj0mIAg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G_Uwk-RcmLQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MIREX\n",
        "(Jazz Transformer)"
      ],
      "metadata": {
        "id": "TvZbqYeID8ce"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T75rwRbTD_E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pitch Class Consistency\n",
        "(Theme Transformer)"
      ],
      "metadata": {
        "id": "1uhxgpk7EAJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HIdusv-MFN2Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}